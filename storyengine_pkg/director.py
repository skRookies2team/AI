import json
import operator
import re
import uuid
from typing import TypedDict, List, Dict, Any, Annotated, Optional
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_core.output_parsers import JsonOutputParser, PydanticOutputParser
from langgraph.graph import StateGraph, END, START
from langgraph.types import Send
from pydantic import BaseModel, Field

from storyengine_pkg.models import (
    Character,
    Gauge,
    FinalEnding,
    EpisodeEnding,
    Episode,
    StoryNode,
    StoryChoice,
    StoryNodeDetail,
)

# Structured Outputì„ ìœ„í•œ Pydantic ìŠ¤í‚¤ë§ˆ
class StoryChoiceSchema(BaseModel):
    """ì„ íƒì§€ ìŠ¤í‚¤ë§ˆ - immediate_reaction í•„ìˆ˜"""
    text: str = Field(description="ì„ íƒì§€ í…ìŠ¤íŠ¸ (80-200ì)")
    tags: List[str] = Field(description="ê²Œì´ì§€ì— ì˜í–¥ì„ ì£¼ëŠ” íƒœê·¸ ë¦¬ìŠ¤íŠ¸")
    immediate_reaction: str = Field(
        description="ì„ íƒ ì§í›„ì˜ ì¦‰ê°ì ì¸ ë°˜ì‘ ë¬˜ì‚¬ (100-200ì). ë°˜ë“œì‹œ í¬í•¨ë˜ì–´ì•¼ í•˜ë©° ë¹„ì›Œë‘˜ ìˆ˜ ì—†ìŒ.",
        min_length=50  # ìµœì†Œ 50ì ê°•ì œ
    )

class StoryNodeSchema(BaseModel):
    """ìŠ¤í† ë¦¬ ë…¸ë“œ ìŠ¤í‚¤ë§ˆ - Structured Outputìš©"""
    text: str = Field(description="ìŠ¤í† ë¦¬ ë³¸ë¬¸ (1200-2000ì)")
    details: Dict[str, Any] = Field(description="ë””í…Œì¼ ì •ë³´ (npc_emotions, situation, relations_update)")
    choices: List[StoryChoiceSchema] = Field(
        description="ì„ íƒì§€ ë¦¬ìŠ¤íŠ¸ (2-4ê°œ). ëª¨ë“  ì„ íƒì§€ëŠ” immediate_reaction í•„ë“œë¥¼ ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•¨.",
        min_items=2,
        max_items=4
    )

# ==============================================================================
# 2. ë©”ì¸ í´ë˜ìŠ¤: ì¸í„°ë™í‹°ë¸Œ ìŠ¤í† ë¦¬ ë””ë ‰í„°
# ==============================================================================

class InteractiveStoryDirector:
    def __init__(self, api_key: str):
        self.llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7, api_key=api_key)
        # Structured Outputìš© LLM (JSON Schema ê°•ì œ ëª¨ë“œ)
        self.structured_llm = self.llm.with_structured_output(StoryNodeSchema)
        self.json_parser = JsonOutputParser()

    # --------------------------------------------------------------------------
    # [2ë‹¨ê³„] ë“±ì¥ì¸ë¬¼ ìë™ ì¶”ì¶œ (Extract Characters)
    # --------------------------------------------------------------------------
    async def extract_characters(self, novel_text: str) -> List[Character]:
        print("ğŸ•µï¸ ë“±ì¥ì¸ë¬¼ ë¶„ì„ ì¤‘...")

        # í…ìŠ¤íŠ¸ì— ì¤„ ë²ˆí˜¸ ì¶”ê°€ (cite ì°¸ì¡°ìš©)
        lines = novel_text.split('\n')

        # ì „ì²´ í…ìŠ¤íŠ¸ ì‚¬ìš© (ë„ˆë¬´ ê¸¸ë©´ ì•/ì¤‘ê°„/ë’¤ ìƒ˜í”Œë§)
        if len(lines) <= 1000:
            selected_lines = lines
        else:
            # ì• 400ì¤„, ì¤‘ê°„ 200ì¤„, ë’¤ 400ì¤„
            mid_start = len(lines) // 2 - 100
            selected_lines = lines[:400] + lines[mid_start:mid_start+200] + lines[-400:]

        numbered_text = '\n'.join([f"[{i+1}] {line}" for i, line in enumerate(selected_lines)])

        prompt = f"""ë‹¹ì‹ ì€ ë¬¸í•™ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì†Œì„¤ í…ìŠ¤íŠ¸ì—ì„œ ì£¼ìš” ë“±ì¥ì¸ë¬¼ë“¤ì˜ ì •ë³´ë¥¼ ìƒì„¸íˆ ì¶”ì¶œí•˜ì„¸ìš”.

[ì†Œì„¤ í…ìŠ¤íŠ¸] (ì¤„ ë²ˆí˜¸ í¬í•¨)
{numbered_text}

[ì¶”ì¶œ í•­ëª©]
ê° ìºë¦­í„°ì— ëŒ€í•´ ë‹¤ìŒ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”:

1. **name**: ì´ë¦„
2. **aliases**: ë³„ëª… ë¦¬ìŠ¤íŠ¸ (í…ìŠ¤íŠ¸ì—ì„œ ë¶ˆë¦¬ëŠ” ë‹¤ë¥¸ í˜¸ì¹­ë“¤)
3. **description**: í†µí•© ì„¤ëª… - ë‹¤ìŒì„ ëª¨ë‘ í¬í•¨í•˜ì—¬ ìƒì„¸íˆ ì‘ì„±:
   - ì™¸í˜• ë¬˜ì‚¬ (ë‚˜ì´, ì‹ ì²´ì  íŠ¹ì§•)
   - ì„±ê²© íŠ¹ì„±
   - ì£¼ìš” í–‰ë™ ë° ì‚¬ê±´
   - ìºë¦­í„°ì˜ ë³€í™”/ì„±ì¥
   - ê° ì •ë³´ì˜ ê·¼ê±°ë¥¼ [cite: ì¤„ë²ˆí˜¸] í˜•ì‹ìœ¼ë¡œ í‘œê¸°

4. **relationships**: ë‹¤ë¥¸ ì¸ë¬¼ê³¼ì˜ ê´€ê³„ ë¦¬ìŠ¤íŠ¸
   - ê° ê´€ê³„ë¥¼ êµ¬ì²´ì ì¸ ì‚¬ê±´/ì¥ë©´ê³¼ í•¨ê»˜ ì„¤ëª…
   - [cite: ì¤„ë²ˆí˜¸] í˜•ì‹ìœ¼ë¡œ ê·¼ê±° í‘œê¸°

[ì˜ˆì‹œ]
{{
    "name": "ë í”„",
    "aliases": ["ê¸ˆë°œì˜ ì†Œë…„", "ëŒ€ì¥"],
    "description": "ê¸ˆë°œì˜ ì†Œë…„ìœ¼ë¡œ [cite: 8, 35], ë§Œ 12ì‚´ì…ë‹ˆë‹¤ [cite: 60]. ë”± ë²Œì–´ì§„ ì–´ê¹¨ì™€ ë¶€ë“œëŸ¬ìš´ ëˆˆê°€ë¥¼ ì§€ë…”ìŠµë‹ˆë‹¤ [cite: 61]. ìˆ˜ì˜ì„ ì˜í•˜ë©° [cite: 90] ì†Œë¼ë¥¼ ë¶ˆì–´ ì•„ì´ë“¤ì„ ì†Œì§‘í–ˆìŠµë‹ˆë‹¤ [cite: 131]. íˆ¬í‘œë¥¼ í†µí•´ ëŒ€ì¥ìœ¼ë¡œ ì„ ì¶œë˜ì—ˆìœ¼ë©° [cite: 224], ë´‰í™”ë¥¼ í”¼ì›Œ êµ¬ì¡°ë˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ ì‚¼ìŠµë‹ˆë‹¤ [cite: 436]. ì‚¬ì´ë¨¼ì˜ ì£½ìŒì— ì£„ì±…ê°ì„ ëŠê¼ˆê³  [cite: 2057], êµ¬ì¡° ì§í›„ ìš¸ìŒì„ í„°ëœ¨ë¦½ë‹ˆë‹¤ [cite: 2687].",
    "relationships": [
        "ìƒˆë¼ë¼ì§€ì™€ ì²˜ìŒ ë§Œë‚˜ í•¨ê»˜ í–‰ë™í•¨ [cite: 8-18]",
        "ì­ê³¼ ë¦¬ë”ì‹­ ë¬¸ì œë¡œ ëŒ€ë¦½í•¨ [cite: 612, 892]",
        "ìƒˆë¼ë¼ì§€ì˜ ë³„ëª…ì„ í­ë¡œí–ˆìœ¼ë‚˜ ë‚˜ì¤‘ì—ëŠ” ì‹ ë¢°í•¨ [cite: 215, 1840]"
    ]
}}

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "characters": [
        {{
            "name": "ìºë¦­í„° ì´ë¦„",
            "aliases": ["ë³„ëª…1", "ë³„ëª…2"],
            "description": "ìƒì„¸ ì„¤ëª… [cite: ì¤„ë²ˆí˜¸]...",
            "relationships": ["ê´€ê³„ ì„¤ëª… [cite: ì¤„ë²ˆí˜¸]", ...]
        }}
    ]
}}"""
        response = await self.llm.ainvoke(prompt)
        characters = self._parse_json(response.content).get("characters", [])

        # ë¹ˆ ê²°ê³¼ì¼ ê²½ìš° ê¸°ë³¸ê°’ ë°˜í™˜
        if not characters:
            print("  âš ï¸ ìºë¦­í„° ì¶”ì¶œ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©")
            return [
                {
                    "name": "ì£¼ì¸ê³µ",
                    "aliases": [],
                    "description": "ì£¼ì¸ê³µì— ëŒ€í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "relationships": []
                }
            ]

        return characters

    # --------------------------------------------------------------------------
    # [3ë‹¨ê³„] ê²Œì´ì§€ ì œì•ˆ (Generate Gauges)
    # --------------------------------------------------------------------------
    async def suggest_gauges(self, novel_summary: str) -> List[Gauge]:
        print("ğŸ“Š ìŠ¤í† ë¦¬ ê²Œì´ì§€ ì„¤ê³„ ì¤‘...")
        prompt = f"""ì´ ì†Œì„¤ì˜ í•µì‹¬ ê°ˆë“±ê³¼ í…Œë§ˆë¥¼ ê´€í†µí•˜ëŠ” 'ê²Œì´ì§€(ìˆ˜ì¹˜)' ì‹œìŠ¤í…œì„ ì„¤ê³„í•˜ë ¤ í•©ë‹ˆë‹¤.
ê°€ì¥ ì ì ˆí•œ 5ê°œì˜ ê²Œì´ì§€ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”.

[ì†Œì„¤ ìš”ì•½]
{novel_summary}

[ìš”êµ¬ì‚¬í•­]
ê° ê²Œì´ì§€ì— ëŒ€í•´ ë‹¤ìŒì„ ì •ì˜í•˜ì„¸ìš”:
- id: ì˜ë¬¸ ì†Œë¬¸ì ì‹ë³„ì (ì˜ˆ: "civilization", "fear")
- name: ê²Œì´ì§€ í•œê¸€ ì´ë¦„ (ì˜ˆ: "ë¬¸ëª…ë„", "ê³µí¬ì‹¬")
- meaning: ì´ ê²Œì´ì§€ê°€ ì˜ë¯¸í•˜ëŠ” ë°” (1-2ë¬¸ì¥)
- min_label: 0ì¼ ë•Œì˜ ìƒíƒœ (ì˜ˆ: "ì•¼ë§Œ", "í‰ì˜¨")
- max_label: 100ì¼ ë•Œì˜ ìƒíƒœ (ì˜ˆ: "ì§ˆì„œ", "ê³µí¬")
- description: ìŠ¤í† ë¦¬ì—ì„œ ì´ ê²Œì´ì§€ê°€ ì–´ë–»ê²Œ ì‚¬ìš©ë˜ëŠ”ì§€ ì„¤ëª…
- initial_value: ì†Œì„¤ ì‹œì‘ ì‹œì ì˜ ì´ˆê¸°ê°’ (0~100, ì†Œì„¤ ìƒí™©ì— ë§ê²Œ ì„¤ì •)
  - ì˜ˆ: í‰í™”ë¡œìš´ ì‹œì‘ì´ë©´ hope=70, ìœ„ê¸° ìƒí™©ì´ë©´ hope=30

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "gauges": [
        {{
            "id": "civilization",
            "name": "ë¬¸ëª…ë„",
            "meaning": "ì‚¬íšŒ ì§ˆì„œì™€ ê·œë²”ì„ ìœ ì§€í•˜ë ¤ëŠ” ì •ë„",
            "min_label": "ì•¼ë§Œ",
            "max_label": "ì§ˆì„œ",
            "description": "ë†’ì„ìˆ˜ë¡ ë¯¼ì£¼ì  ë¦¬ë”ì‹­ê³¼ ê·œì¹™ì„ ë”°ë¥´ê³ , ë‚®ì„ìˆ˜ë¡ ë³¸ëŠ¥ê³¼ í­ë ¥ì— ì˜ì¡´",
            "initial_value": 65
        }}
    ]
}}"""
        response = await self.llm.ainvoke(prompt)
        gauges = self._parse_json(response.content).get("gauges", [])

        # ë¹ˆ ê²°ê³¼ì¼ ê²½ìš° ê¸°ë³¸ê°’ ë°˜í™˜
        if not gauges:
            print("  âš ï¸ ê²Œì´ì§€ ì œì•ˆ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©")
            return [
                {
                    "id": "progress",
                    "name": "ì§„í–‰ë„",
                    "meaning": "ìŠ¤í† ë¦¬ ì§„í–‰ ìƒí™©",
                    "min_label": "ì‹œì‘",
                    "max_label": "ì™„ë£Œ",
                    "description": "ìŠ¤í† ë¦¬ê°€ ì–¼ë§ˆë‚˜ ì§„í–‰ë˜ì—ˆëŠ”ì§€ ë‚˜íƒ€ëƒ„"
                }
            ]

        return gauges

    # --------------------------------------------------------------------------
    # [4ë‹¨ê³„] ìµœì¢… ì—”ë”© ìƒì„± (Generate Final Endings - ê²Œì´ì§€ ëˆ„ì  ê¸°ë°˜)
    # --------------------------------------------------------------------------
    async def design_final_endings(
        self,
        novel_summary: str,
        selected_gauges: List[Gauge],
        ending_config: Dict[str, int] = None
    ) -> List[FinalEnding]:
        """
        ìµœì¢… ì—”ë”© ì„¤ê³„

        Args:
            ending_config: ì—”ë”© íƒ€ì…ë³„ ê°œìˆ˜ ì„¤ì •
                ì˜ˆ: {"happy": 2, "tragic": 1, "neutral": 1, "open": 1}
                ì§€ì› íƒ€ì…: happy, tragic, neutral, open, bad, bittersweet
        """
        # ê¸°ë³¸ê°’ ì„¤ì •
        if ending_config is None:
            ending_config = {"happy": 2, "tragic": 1, "neutral": 1, "open": 1}

        total_endings = sum(ending_config.values())
        print(f"ğŸ ìµœì¢… ì—”ë”© ì„¤ê³„ ì¤‘ ({total_endings}ê°œ)...")

        # ê²Œì´ì§€ ì •ë³´ í¬ë§·íŒ…
        gauges_detail = []
        for g in selected_gauges:
            gauge_str = f"â€¢ {g.get('name', '?')} ({g.get('id', '?')}): {g.get('min_label', '?')} (0) â†” {g.get('max_label', '?')} (100)"
            gauges_detail.append(gauge_str)
        gauges_info = "\n".join(gauges_detail)

        # ì—”ë”© íƒ€ì… ìš”êµ¬ì‚¬í•­ ìƒì„±
        ending_requirements = []
        type_descriptions = {
            "happy": "í–‰ë³µí•œ ì—”ë”© (í¬ë§ì ì¸ ê²°ë§, ëª©í‘œ ë‹¬ì„±)",
            "tragic": "ë¹„ê·¹ì ì¸ ì—”ë”© (íŒŒë©¸, ì£½ìŒ, ì‹¤íŒ¨)",
            "neutral": "ì¤‘ë¦½ì ì¸ ì—”ë”© (ë¬´ë‚œí•œ ê²°ë§, í° ë³€í™” ì—†ìŒ)",
            "open": "ì—´ë¦° ê²°ë§ (í•´ì„ì˜ ì—¬ì§€, ë¯¸ì™„ì˜ ì´ì•¼ê¸°)",
            "bad": "ë‚˜ìœ ì—”ë”© (ë¶ˆí–‰í•œ ê²°ë§, ì†ì‹¤)",
            "bittersweet": "ì”ì“¸í•œ ì—”ë”© (í¬ìƒì„ í†µí•œ ì„±ê³µ, ë‹¬ì½¤ì“´ ê²°ë§)"
        }

        for ending_type, count in ending_config.items():
            if count > 0:
                desc = type_descriptions.get(ending_type, ending_type)
                ending_requirements.append(f"- {desc}: {count}ê°œ")

        ending_requirements_str = "\n".join(ending_requirements)

        prompt = f"""ì„ íƒëœ ê²Œì´ì§€ì˜ ìµœì¢… ëˆ„ì  ìˆ˜ì¹˜ì— ë”°ë¼ ë„ë‹¬í•  ìˆ˜ ìˆëŠ” ìµœì¢… ì—”ë”©ì„ ì„¤ê³„í•˜ì„¸ìš”.

[ì†Œì„¤ ìš”ì•½]
{novel_summary}

[ê²Œì´ì§€ ì‹œìŠ¤í…œ]
{gauges_info}

[ì—”ë”© íƒ€ì…ë³„ ìš”êµ¬ì‚¬í•­]
ë‹¤ìŒ íƒ€ì…ê³¼ ê°œìˆ˜ì— ë§ì¶° ì—”ë”©ì„ ìƒì„±í•´ì£¼ì„¸ìš”:
{ending_requirements_str}

ì´ {total_endings}ê°œì˜ ì—”ë”©ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤. 

[ì¤‘ìš”]
- ì´ ì—”ë”©ë“¤ì€ ì—¬ëŸ¬ ì—í”¼ì†Œë“œë¥¼ ê±°ì¹œ í›„ ëˆ„ì ëœ ê²Œì´ì§€ ê°’ìœ¼ë¡œ ê²°ì •ë©ë‹ˆë‹¤.
- ê° ì—í”¼ì†Œë“œ ì—”ë”©ì—ì„œ ê²Œì´ì§€ê°€ +/- ë˜ì–´ ìµœì¢… ê°’ì´ ê²°ì •ë©ë‹ˆë‹¤.
- ê²Œì´ì§€ ì´ˆê¸°ê°’ì€ 50ì´ë©°, 0~100 ë²”ìœ„ì…ë‹ˆë‹¤.

[ìš”êµ¬ì‚¬í•­]
ê° ì—”ë”©ì— ëŒ€í•´ ë‹¤ìŒì„ ì •ì˜í•˜ì„¸ìš”:
- id: ì˜ë¬¸ ì†Œë¬¸ì ì‹ë³„ì (ì˜ˆ: "ending_hope", "ending_despair")
- type: ì—”ë”© íƒ€ì… (ì˜ˆ: "happy", "bad", "neutral", "tragic", "open")
- title: ì—”ë”© ì œëª© (ì˜ˆ: "êµ¬ì¡°ì˜ í¬ë§", "ì•¼ë§Œìœ¼ë¡œì˜ ì¶”ë½")
- condition: ë„ë‹¬ ì¡°ê±´ - ìµœì¢… ê²Œì´ì§€ ìƒíƒœ (ì˜ˆ: "hope >= 70 AND despair <= 30")
- summary: ì—”ë”© ë‚´ìš© ìš”ì•½ (3-5ë¬¸ì¥)

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "endings": [
        {{
            "id": "ending_hope",
            "type": "happy",
            "title": "êµ¬ì¡°ì˜ í¬ë§",
            "condition": "hope >= 70 AND trust >= 60",
            "summary": "ì†Œë…„ë“¤ì€ ëê¹Œì§€ í¬ë§ì„ ìƒì§€ ì•Šê³  ì„œë¡œë¥¼ ì‹ ë¢°í–ˆë‹¤. ë§ˆì¹¨ë‚´ êµ¬ì¡°ì„ ì´ ë„ì°©í•˜ê³ , ëª¨ë‘ê°€ ì•ˆì „í•˜ê²Œ ëŒì•„ê°„ë‹¤."
        }},
        {{
            "id": "ending_despair",
            "type": "tragic",
            "title": "ì ˆë§ì˜ ë‚˜ë½",
            "condition": "despair >= 70 AND trust <= 30",
            "summary": "ì ˆë§ì´ ëª¨ë“  ê²ƒì„ ì§‘ì–´ì‚¼ì¼°ë‹¤. ì„œë¡œì— ëŒ€í•œ ì‹ ë¢°ëŠ” ë¬´ë„ˆì§€ê³ , ë¹„ê·¹ì ì¸ ê²°ë§ì„ ë§ì´í•œë‹¤."
        }}
    ]
}}"""
        response = await self.llm.ainvoke(prompt)
        endings = self._parse_json(response.content).get("endings", [])

        # ë¹ˆ ê²°ê³¼ì¼ ê²½ìš° ê¸°ë³¸ê°’ ë°˜í™˜
        if not endings:
            print("  âš ï¸ ìµœì¢… ì—”ë”© ì„¤ê³„ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©")
            return [
                {
                    "id": "ending_default",
                    "type": "neutral",
                    "title": "ê¸°ë³¸ ì—”ë”©",
                    "condition": "default",
                    "summary": "ìŠ¤í† ë¦¬ê°€ ê¸°ë³¸ì ì¸ ê²°ë§ì— ë„ë‹¬í•©ë‹ˆë‹¤."
                }
            ]

        print(f"  âœ… {len(endings)}ê°œì˜ ìµœì¢… ì—”ë”© ì„¤ê³„ ì™„ë£Œ")
        return endings

    # --------------------------------------------------------------------------
    # [5ë‹¨ê³„] ì—í”¼ì†Œë“œ ë¶„í•  (Split into Episodes)
    # --------------------------------------------------------------------------
    async def split_into_episodes(self, novel_summary: str, characters: List[Character], num_episodes: int = 4) -> List[Dict]:
        print(f"ğŸ“š ì†Œì„¤ì„ {num_episodes}ê°œ ì—í”¼ì†Œë“œë¡œ ë¶„í•  ì¤‘...")

        # ìºë¦­í„° ì´ë¦„ ëª©ë¡
        char_names = [c.get('name', 'ì´ë¦„ì—†ìŒ') for c in characters]

        prompt = f"""ì£¼ì–´ì§„ ì†Œì„¤ì„ {num_episodes}ê°œì˜ ë…ë¦½ì ì¸ ì—í”¼ì†Œë“œë¡œ ë¶„í• í•˜ì„¸ìš”.

[ì†Œì„¤ ìš”ì•½]
{novel_summary}

[ë“±ì¥ì¸ë¬¼]
{', '.join(char_names)}

[ì¤‘ìš” ê·œì¹™]
- ê° ì—í”¼ì†Œë“œëŠ” ìŠ¤í† ë¦¬ìƒ ì„œë¡œ ì—°ê²°ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤ (ë…ë¦½ì )
- ì—í”¼ì†Œë“œ ê°„ì—ëŠ” ì˜¤ì§ ê²Œì´ì§€ë§Œ ëˆ„ì ë©ë‹ˆë‹¤
- ê° ì—í”¼ì†Œë“œëŠ” ìì²´ì ì¸ ì‹œì‘, ì „ê°œ, ì—”ë”©ì„ ê°€ì§‘ë‹ˆë‹¤

[ìš”êµ¬ì‚¬í•­]
ê° ì—í”¼ì†Œë“œì— ëŒ€í•´ ë‹¤ìŒì„ ì •ì˜í•˜ì„¸ìš”:
- id: ì˜ë¬¸ ì†Œë¬¸ì ì‹ë³„ì (ì˜ˆ: "ep1_encounter")
- title: ì—í”¼ì†Œë“œ ì œëª©
- order: ìˆœì„œ (1, 2, 3...)
- description: ì—í”¼ì†Œë“œ ìš”ì•½ (2-3ë¬¸ì¥)
- theme: í•µì‹¬ í…Œë§ˆ/ê°ˆë“± (ì˜ˆ: "ì‹ ë¢° vs ì˜ì‹¬", "í¬ë§ vs ì ˆë§")
- key_characters: ì£¼ìš” ë“±ì¥ì¸ë¬¼ ë¦¬ìŠ¤íŠ¸

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "episodes": [
        {{
            "id": "ep1_encounter",
            "title": "ì²« ë§Œë‚¨",
            "order": 1,
            "description": "ì£¼ì¸ê³µë“¤ì´ ì²˜ìŒ ë§Œë‚˜ ì„œë¡œë¥¼ ì•Œì•„ê°€ëŠ” ê³¼ì •. ì²«ì¸ìƒê³¼ ì´ˆê¸° ê´€ê³„ê°€ í˜•ì„±ëœë‹¤.",
            "theme": "ì‹ ë¢° í˜•ì„±",
            "key_characters": ["ë í”„", "ì­", "ìƒˆë¼ë¼ì§€"]
        }}
    ]
}}"""
        response = await self.llm.ainvoke(prompt)
        episodes = self._parse_json(response.content).get("episodes", [])

        if not episodes:
            print("  âš ï¸ ì—í”¼ì†Œë“œ ë¶„í•  ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©")
            return [
                {
                    "id": "ep1_default",
                    "title": "ì—í”¼ì†Œë“œ 1",
                    "order": 1,
                    "description": "ê¸°ë³¸ ì—í”¼ì†Œë“œ",
                    "theme": "ê¸°ë³¸",
                    "key_characters": char_names[:3]
                }
            ]

        print(f"  âœ… {len(episodes)}ê°œ ì—í”¼ì†Œë“œ ë¶„í•  ì™„ë£Œ")
        for ep in episodes:
            print(f"    â€¢ [{ep.get('order', '?')}] {ep.get('title', 'ì œëª©ì—†ìŒ')}: {ep.get('theme', '')}")

        return episodes

    # --------------------------------------------------------------------------
    # [5-2ë‹¨ê³„] ì—í”¼ì†Œë“œ ë„ì…ë¶€ ìƒì„± (Generate Episode Intro)
    # --------------------------------------------------------------------------
    async def generate_episode_intro(self, episode: Dict, characters: List[Character], novel_summary: str) -> str:
        print(f"  ğŸ¬ '{episode.get('title', '?')}' ë„ì…ë¶€ ìƒì„± ì¤‘...")

        # ìºë¦­í„° ì •ë³´
        char_names = [c.get('name', 'ì´ë¦„ì—†ìŒ') for c in characters]

        prompt = f"""ë‹¤ìŒ ì—í”¼ì†Œë“œì˜ ë„ì…ë¶€ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
í”Œë ˆì´ì–´ê°€ ì²« ë²ˆì§¸ ì„ íƒì§€ë¥¼ ë§Œë‚˜ê¸° ì „ì— ì½ê²Œ ë˜ëŠ” ìŠ¤í† ë¦¬ì…ë‹ˆë‹¤.
ì´ê²ƒì€ í”Œë ˆì´ì–´ê°€ ì—í”¼ì†Œë“œì—ì„œ ê°€ì¥ ë¨¼ì € ì ‘í•˜ëŠ” í…ìŠ¤íŠ¸ì´ë¯€ë¡œ, ê°•ë ¬í•œ ì²«ì¸ìƒê³¼ ëª°ì…ê°ì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.

[ì†Œì„¤ ë°°ê²½]
{novel_summary}

[ì—í”¼ì†Œë“œ ì •ë³´]
- ì œëª©: {episode.get('title', '?')}
- ì„¤ëª…: {episode.get('description', '?')}
- í…Œë§ˆ: {episode.get('theme', '?')}
- ì£¼ìš” ë“±ì¥ì¸ë¬¼: {', '.join(episode.get('key_characters', char_names[:3]))}

[ì‘ì„± ìš”êµ¬ì‚¬í•­]
1. **ë¶„ëŸ‰**: 1500~2500ì (ì¶©ë¶„íˆ ê¸¸ê²Œ ì‘ì„±í•˜ì—¬ ì™„ì „í•œ ëª°ì… ì œê³µ)

2. **í•„ìˆ˜ í¬í•¨ ìš”ì†Œ**:

   ğŸ¬ **ê°•ë ¬í•œ ì²« ë¬¸ì¥** (í›„í¬):
   - ë…ìì˜ í˜¸ê¸°ì‹¬ì„ ì¦‰ì‹œ ìê·¹í•˜ëŠ” ì‹œì‘
   - ì˜ˆ: "ê·¸ë‚  ë°¤, ëª¨ë“  ê²ƒì´ ë‹¬ë¼ì¡Œë‹¤." / "í”¼ ëƒ„ìƒˆê°€ ê³µê¸°ë¥¼ ê°€ë“ ì±„ì› ë‹¤."

   ğŸŒ… **ë¶„ìœ„ê¸°ì™€ í™˜ê²½ ë¬˜ì‚¬** (300-500ì):
   - ì‹œê°„ëŒ€, ë‚ ì”¨, ì£¼ë³€ í™˜ê²½ì˜ ì‹œê°ì /ì²­ê°ì  ë””í…Œì¼
   - ì˜¤ê°ì„ í™œìš©í•œ ìƒìƒí•œ ë¬˜ì‚¬
   - ë¶„ìœ„ê¸°ê°€ ì—í”¼ì†Œë“œ í…Œë§ˆì™€ ì—°ê²°ë˜ë„ë¡

   ğŸ‘¥ **ë“±ì¥ì¸ë¬¼ ì†Œê°œì™€ í˜„ì¬ ìƒíƒœ** (400-600ì):
   - ì£¼ìš” ìºë¦­í„°ë“¤ì˜ í˜„ì¬ ê°ì • ìƒíƒœ
   - ìºë¦­í„° ê°„ ê¸´ì¥ê°ì´ë‚˜ ê´€ê³„ì˜ ë¯¸ë¬˜í•œ ë³€í™”
   - ê²‰ìœ¼ë¡œ ë³´ì´ëŠ” ëª¨ìŠµê³¼ ë‚´ë©´ì˜ ê°ì • ëŒ€ì¡°

   ğŸ—£ï¸ **ëŒ€í™”ì™€ ìƒí˜¸ì‘ìš©** (400-600ì):
   - ìµœì†Œ 2-3íšŒì˜ ì˜ë¯¸ ìˆëŠ” ëŒ€í™” êµí™˜
   - ëŒ€í™”ë¥¼ í†µí•´ ìºë¦­í„° ì„±ê²©ê³¼ í˜„ì¬ ê°ˆë“± ë“œëŸ¬ë‚´ê¸°
   - ëŒ€í™” ì¤‘ í‘œì •, ëª¸ì§“, ì¹¨ë¬µì˜ ì˜ë¯¸ í¬í•¨

   âš¡ **í•µì‹¬ ê°ˆë“±/ìœ„ê¸° ì œì‹œ** (300-400ì):
   - ì´ ì—í”¼ì†Œë“œì—ì„œ ë‹¤ë£° í•µì‹¬ ë¬¸ì œë¥¼ ì•”ì‹œ
   - ê¸´ì¥ê°ì„ ì ì§„ì ìœ¼ë¡œ ë†’ì´ê¸°
   - í”Œë ˆì´ì–´ê°€ "ë‹¤ìŒì— ë¬´ìŠ¨ ì¼ì´?"ë¼ê³  ê¶ê¸ˆí•´í•˜ë„ë¡

   ğŸ­ **ì„ íƒì˜ ìˆœê°„ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ì „í™˜** (100-200ì):
   - "ê·¸ë•Œ, ë‹¹ì‹ ì€ ê²°ì •í•´ì•¼ í–ˆë‹¤..." ê°™ì€ ì „í™˜
   - í”Œë ˆì´ì–´ê°€ ê³§ ì¤‘ìš”í•œ ì„ íƒì„ í•˜ê²Œ ë  ê²ƒì„ì„ ì•”ì‹œ

3. **ì‘ì„± ìŠ¤íƒ€ì¼**:
   - ì˜í™”ì˜ ì˜¤í”„ë‹ ì”¬ì²˜ëŸ¼ ê·¹ì ì´ê³  ìƒìƒí•˜ê²Œ
   - ë‚´ì  ë…ë°±ì„ í™œìš©í•˜ì—¬ ìºë¦­í„°ì˜ ì§„ì§œ ê°ì • í‘œí˜„
   - ì§§ì€ ë¬¸ì¥ê³¼ ê¸´ ë¬¸ì¥ì„ ì„ì–´ ë¦¬ë“¬ê° ì¡°ì ˆ
   - ê¸´ì¥ê°ì´ ì ì  ê³ ì¡°ë˜ë„ë¡ êµ¬ì„±

4. **ì˜ˆì‹œ êµ¬ì¡°**:
   [ê°•ë ¬í•œ ì²« ë¬¸ì¥]

   [í™˜ê²½ê³¼ ë¶„ìœ„ê¸° ë¬˜ì‚¬ - ì˜¤ê° í™œìš©]

   [ìºë¦­í„° ë“±ì¥ ë° í˜„ì¬ ìƒíƒœ ë¬˜ì‚¬]

   [ì˜ë¯¸ ìˆëŠ” ëŒ€í™” 1]
   [ëŒ€í™” ì¤‘ í–‰ë™/í‘œì • ë¬˜ì‚¬]
   [ì˜ë¯¸ ìˆëŠ” ëŒ€í™” 2]

   [ë‚´ì  ë…ë°± - ìºë¦­í„°ì˜ ì§„ì§œ ìƒê°]

   [í•µì‹¬ ê°ˆë“±/ìœ„ê¸° ì œì‹œ]

   [ì„ íƒì˜ ìˆœê°„ìœ¼ë¡œ ì „í™˜]

ë„ì…ë¶€ í…ìŠ¤íŠ¸ë§Œ ì‘ì„±í•´ì£¼ì„¸ìš” (JSON í˜•ì‹ ì•„ë‹˜, ìˆœìˆ˜ í…ìŠ¤íŠ¸):"""

        response = await self.llm.ainvoke(prompt)
        intro_text = response.content.strip()

        print(f"    âœ… ë„ì…ë¶€ ìƒì„± ì™„ë£Œ ({len(intro_text)}ì)")
        return intro_text

    # --------------------------------------------------------------------------
    # [6ë‹¨ê³„] ì—í”¼ì†Œë“œ ì—”ë”© ì„¤ê³„ (Design Episode Endings)
    # --------------------------------------------------------------------------
    async def design_episode_endings(self, episode: Dict, selected_gauges: List[Gauge], num_endings: int = 3) -> List[EpisodeEnding]:
        print(f"  ğŸ¯ '{episode.get('title', '?')}' ì—í”¼ì†Œë“œ ì—”ë”© ì„¤ê³„ ì¤‘...")

        # ê²Œì´ì§€ ì •ë³´ í¬ë§·íŒ…
        gauges_info = self._format_gauges(selected_gauges)

        prompt = f"""ì´ ì—í”¼ì†Œë“œì˜ {num_endings}ê°€ì§€ ì—”ë”©ì„ ì„¤ê³„í•˜ì„¸ìš”. ê° ì—”ë”©ì€ í”Œë ˆì´ì–´ì˜ ì„ íƒ íƒœê·¸ ëˆ„ì ì— ë”°ë¼ ë„ë‹¬í•˜ë©°, ê²Œì´ì§€ì— ì˜í–¥ì„ ì¤ë‹ˆë‹¤.

[ì—í”¼ì†Œë“œ ì •ë³´]
- ì œëª©: {episode.get('title', '?')}
- ì„¤ëª…: {episode.get('description', '?')}
- í…Œë§ˆ: {episode.get('theme', '?')}

[ê²Œì´ì§€ ì‹œìŠ¤í…œ]
{gauges_info}

[ì„ íƒì§€ íƒœê·¸ ì‹œìŠ¤í…œ]
í”Œë ˆì´ì–´ê°€ ì„ íƒì§€ë¥¼ ê³ ë¥¼ ë•Œë§ˆë‹¤ í•´ë‹¹ íƒœê·¸ê°€ ëˆ„ì ë©ë‹ˆë‹¤.
ì‚¬ìš© ê°€ëŠ¥í•œ íƒœê·¸: cooperative, aggressive, cautious, trusting, doubtful, brave, fearful, rational, emotional

[ì¤‘ìš”]
- ê° ì—”ë”©ì—ì„œë§Œ ê²Œì´ì§€ê°€ ë³€í™”í•©ë‹ˆë‹¤
- ê²Œì´ì§€ ë³€í™”ëŸ‰ì€ ì—”ë”©ì˜ ì¤‘ìš”ë„ì™€ ê·¹ì  íš¨ê³¼ì— ë”°ë¼ ììœ ë¡­ê²Œ ì„¤ì •í•˜ì„¸ìš”:
  - ì‘ì€ ì˜í–¥: -10 ~ +10
  - ë³´í†µ ì˜í–¥: -20 ~ +20
  - í° ì˜í–¥ (ê·¹ì ì¸ ì—”ë”©): -30 ~ +30
- conditionì€ íƒœê·¸ ì ìˆ˜ ê¸°ë°˜ ì¡°ê±´ì‹ìœ¼ë¡œ ì‘ì„± (ì˜ˆ: "cooperative >= 2", "trusting > doubtful")

[ìš”êµ¬ì‚¬í•­]
ê° ì—”ë”©ì— ëŒ€í•´ ë‹¤ìŒì„ ì •ì˜í•˜ì„¸ìš”:
- id: ì˜ë¬¸ ì†Œë¬¸ì ì‹ë³„ì
- title: ì—”ë”© ì œëª© (ê°ì •ì  ìš¸ë¦¼ì´ ìˆëŠ” ì œëª©)
- condition: íƒœê·¸ ê¸°ë°˜ ì¡°ê±´ì‹ (ì˜ˆ: "cooperative >= 2 AND trusting >= 1")
- text: ì—”ë”© í…ìŠ¤íŠ¸ (800-1500ì) - í”Œë ˆì´ì–´ì˜ ì„ íƒì´ ë§Œë“  ê²°ê³¼ë¥¼ ê¹Šì´ ìˆê²Œ í‘œí˜„:

  ğŸ“– **ì—”ë”© í…ìŠ¤íŠ¸ ì‘ì„± ê°€ì´ë“œ** (800-1500ì):

  1. **í´ë¼ì´ë§¥ìŠ¤ ì¥ë©´** (300-400ì):
     - í”Œë ˆì´ì–´ì˜ ì„ íƒì´ ê²°ì‹¤ì„ ë§ºëŠ” ê·¹ì ì¸ ìˆœê°„
     - ê¸´ì¥ê°ì˜ ì •ì ê³¼ í•´ì†Œ
     - ì‹œê°ì ìœ¼ë¡œ ê°•ë ¬í•œ ì¥ë©´ ë¬˜ì‚¬

  2. **ìºë¦­í„° ë°˜ì‘ê³¼ ê°ì •** (200-300ì):
     - ì£¼ìš” ìºë¦­í„°ë“¤ì˜ ê°ì • ë³€í™”
     - ë‚´ì  ë…ë°±ìœ¼ë¡œ ì§„ì‹¬ í‘œí˜„
     - ê´€ê³„ì˜ ë³€í™”ê°€ ë§Œë“  ì˜í–¥

  3. **ì„ íƒì˜ ê²°ê³¼ì™€ ì˜ë¯¸** (200-300ì):
     - í”Œë ˆì´ì–´ì˜ ì„ íƒì´ ê°€ì ¸ì˜¨ êµ¬ì²´ì  ê²°ê³¼
     - "ë‹¹ì‹ ì˜ ì„ íƒì€..." í˜•ì‹ìœ¼ë¡œ ì§ì ‘ ì–¸ê¸‰
     - ì„ íƒì˜ ë¬´ê²Œê°ê³¼ ì˜ë¯¸ ë¶€ì—¬

  4. **ì—¬ìš´ê³¼ ë‹¤ìŒ ì—í”¼ì†Œë“œ ì•”ì‹œ** (100-200ì):
     - ê°ì •ì  ì—¬ìš´ì´ ë‚¨ëŠ” ë§ˆë¬´ë¦¬
     - ë‹¤ìŒì— ì¼ì–´ë‚  ì¼ì— ëŒ€í•œ ì•”ì‹œ
     - í”Œë ˆì´ì–´ê°€ ê³„ì† í”Œë ˆì´í•˜ê³  ì‹¶ê²Œ ë§Œë“¤ê¸°

  ì˜ˆì‹œ ìŠ¤íƒ€ì¼:
  "ë‹¹ì‹ ì€ ìš©ê¸°ë¥¼ ë‚´ì–´ ì§„ì‹¤ì„ ë§í•˜ê¸°ë¡œ ê²°ì •í–ˆë‹¤.

  ë í”„ì˜ ëˆˆì´ ì»¤ì¡Œë‹¤. ê·¸ëŠ” í•œë™ì•ˆ ì•„ë¬´ ë§ë„ í•˜ì§€ ëª»í–ˆë‹¤. ëª¨ë‹¥ë¶ˆì˜ ë¶ˆë¹›ì´ ê·¸ì˜ ì–¼êµ´ì—
  ìš”ë™ì¹˜ëŠ” ê·¸ë¦¼ìë¥¼ ë“œë¦¬ì› ë‹¤. ë§ˆì¹¨ë‚´ ê·¸ê°€ ì…ì„ ì—´ì—ˆë‹¤. 'ê³ ë§ˆì›Œ... ë„¤ê°€ ì†”ì§í•˜ê²Œ
  ë§í•´ì¤˜ì„œ.' ëª©ì†Œë¦¬ëŠ” ë–¨ë ¸ì§€ë§Œ ì§„ì‹¬ì´ ë‹´ê²¨ ìˆì—ˆë‹¤.

  ë‹¤ë¥¸ ì•„ì´ë“¤ë„ ì¹¨ë¬µ ì†ì—ì„œ ë‹¹ì‹ ì„ ë°”ë¼ë´¤ë‹¤. ìƒˆë¼ë¼ì§€ëŠ” ì•ˆê²½ ë„ˆë¨¸ë¡œ ê°ì‚¬ì˜ ëˆˆë¹›ì„
  ë³´ëƒˆë‹¤. ì‹¬ì§€ì–´ ì­ì¡°ì°¨ ì ì‹œ ì‚¬ëƒ¥ ì–˜ê¸°ë¥¼ ë©ˆì·„ë‹¤.

  ë‹¹ì‹ ì˜ ì„ íƒì€ ì´ë“¤ì—ê²Œ ì‘ì€ ìš©ê¸°ë¥¼ ì‹¬ì–´ì£¼ì—ˆë‹¤. ì§„ì‹¤ì€ ë•Œë¡œ ê³ í†µìŠ¤ëŸ½ì§€ë§Œ,
  ê±°ì§“ë³´ë‹¤ëŠ” ë‚«ë‹¤ëŠ” ê²ƒì„ ëª¨ë‘ê°€ ëŠê¼ˆë‹¤.

  í•˜ì§€ë§Œ ì„¬ì˜ ì–´ë‘ ì€ ì—¬ì „íˆ ê¹Šì—ˆê³ , ì•ìœ¼ë¡œ ë” ì–´ë ¤ìš´ ì‹œë ¨ì´ ê¸°ë‹¤ë¦¬ê³  ìˆì—ˆë‹¤..."

- gauge_changes: ê²Œì´ì§€ ë³€í™” (ì˜ˆ: {{'hope': 15, 'trust': 10}})

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "endings": [
        {{
            "id": "ep1_ending_trust",
            "title": "ì‹ ë¢°ì˜ ì‹œì‘",
            "condition": "cooperative >= 2 AND trusting >= 1",
            "text": "ì„œë¡œë¥¼ ì•Œì•„ê°€ë©° ì‹ ë¢°ê°€ ì‹¹í…„ë‹¤. ì•„ì§ ì™„ì „í•˜ì§€ëŠ” ì•Šì§€ë§Œ, í•¨ê»˜í•  ìˆ˜ ìˆë‹¤ëŠ” í¬ë§ì´ ìƒê²¼ë‹¤.",
            "gauge_changes": {{"hope": 10, "trust": 15}}
        }},
        {{
            "id": "ep1_ending_doubt",
            "title": "ì˜ì‹¬ì˜ ì”¨ì•—",
            "condition": "doubtful >= 2 OR aggressive >= 2",
            "text": "ì„œë¡œë¥¼ ê²½ê³„í•˜ë©° ê±°ë¦¬ë¥¼ ë‘ì—ˆë‹¤. ë¶ˆì‹ ì˜ ì”¨ì•—ì´ ë§ˆìŒ ì†ì— ì‹¬ì–´ì¡Œë‹¤.",
            "gauge_changes": {{"hope": -5, "trust": -10}}
        }},
        {{
            "id": "ep1_ending_neutral",
            "title": "ì¡°ì‹¬ìŠ¤ëŸ¬ìš´ ê´€ë§",
            "condition": "default",
            "text": "íŠ¹ë³„í•œ ì§„ì „ ì—†ì´ ì—í”¼ì†Œë“œê°€ ë§ˆë¬´ë¦¬ë˜ì—ˆë‹¤. ì•„ì§ ì„œë¡œì— ëŒ€í•´ ì•Œì•„ê°€ëŠ” ì¤‘ì´ë‹¤.",
            "gauge_changes": {{"hope": 0, "trust": 0}}
        }}
    ]
}}"""
        response = await self.llm.ainvoke(prompt)
        endings = self._parse_json(response.content).get("endings", [])

        if not endings:
            print(f"    âš ï¸ ì—í”¼ì†Œë“œ ì—”ë”© ì„¤ê³„ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©")
            return [
                {
                    "id": f"{episode.get('id', 'ep')}_ending_default",
                    "title": "ê¸°ë³¸ ì—”ë”©",
                    "condition": "ê¸°ë³¸",
                    "text": "ì—í”¼ì†Œë“œê°€ ëë‚¬ìŠµë‹ˆë‹¤.",
                    "gauge_changes": {{}}
                }
            ]

        print(f"    âœ… {len(endings)}ê°œ ì—”ë”© ì„¤ê³„ ì™„ë£Œ")
        return endings

    # --------------------------------------------------------------------------
    # [5ë‹¨ê³„] ìŠ¤í† ë¦¬ íŠ¸ë¦¬ ìƒì„± (Generate Story Tree - LangGraph Engine)
    # --------------------------------------------------------------------------
    async def generate_full_tree(self, context: Dict, max_depth: int = 3) -> List[StoryNode]:
        """
        LangGraphë¥¼ ì‚¬ìš©í•˜ì—¬ ì „ì²´ ìŠ¤í† ë¦¬ íŠ¸ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            context: ìºë¦­í„°, ê²Œì´ì§€, ì—”ë”©, êµ¬ì¡°ê°€ì´ë“œ, ì†Œì„¤ìš”ì•½ ë“± ëª¨ë“  ì»¨í…ìŠ¤íŠ¸ ì •ë³´
            max_depth: íŠ¸ë¦¬ì˜ ìµœëŒ€ ê¹Šì´ (ê¸°ë³¸ê°’: 3)

        Returns:
            ìƒì„±ëœ ëª¨ë“  StoryNode ë¦¬ìŠ¤íŠ¸

        Note:
            - ê¹Šì´ 0: ë£¨íŠ¸ ë…¸ë“œ (1ê°œ)
            - ê¹Šì´ 1: ë£¨íŠ¸ì˜ ì„ íƒì§€ ìˆ˜ë§Œí¼ (ì˜ˆ: 3ê°œ)
            - ê¹Šì´ 2: ê¹Šì´1 ë…¸ë“œë“¤ì˜ ì„ íƒì§€ ì´í•© (ì˜ˆ: 9ê°œ)
            - ...
            - ê¸°í•˜ê¸‰ìˆ˜ì ìœ¼ë¡œ ì¦ê°€í•˜ë¯€ë¡œ max_depthë¥¼ ì ì ˆíˆ ì„¤ì •í•´ì•¼ í•¨
        """
        print(f"ğŸŒ³ ìŠ¤í† ë¦¬ íŠ¸ë¦¬ ìƒì„± ì—”ì§„ ê°€ë™... (ìµœëŒ€ ê¹Šì´: {max_depth})")

        # ì˜ˆìƒ ë…¸ë“œ ìˆ˜ ê³„ì‚° (ì„ íƒì§€ê°€ í‰ê·  3ê°œë¼ ê°€ì •)
        avg_choices = 3
        estimated_nodes = sum([avg_choices ** d for d in range(max_depth + 1)])
        print(f"  ğŸ“Š ì˜ˆìƒ ë…¸ë“œ ìˆ˜: ì•½ {estimated_nodes}ê°œ")

        # LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±
        workflow = StateGraph(StoryGenerationState)
        workflow.add_node("generate_node", self._node_generator)
        workflow.add_edge(START, "generate_node")
        workflow.add_conditional_edges("generate_node", self._plan_next_step)

        app = workflow.compile()

        # ì´ˆê¸° ê²Œì´ì§€ ìƒíƒœ ì„¤ì • (AIê°€ ì œì•ˆí•œ initial_value ì‚¬ìš©, ì—†ìœ¼ë©´ 50)
        initial_gauges = {}
        for gauge in context.get("gauges", []):
            gauge_id = gauge.get("id", gauge.get("name", "unknown"))
            initial_gauges[gauge_id] = gauge.get("initial_value", 50)

        # ì´ˆê¸° ìƒíƒœ ì£¼ì…
        initial_state: StoryGenerationState = {
            "nodes": [],
            "context": context,
            "max_depth": max_depth,
            "current_gauges": initial_gauges
        }

        try:
            final_state = await app.ainvoke(initial_state)
            nodes = final_state.get("nodes", [])

            print(f"âœ… íŠ¸ë¦¬ ìƒì„± ì™„ë£Œ! ì´ {len(nodes)}ê°œ ë…¸ë“œ ìƒì„±ë¨")

            # íŠ¸ë¦¬ êµ¬ì¡° ìš”ì•½ ì¶œë ¥
            self._print_tree_summary(nodes)

            return nodes

        except Exception as e:
            print(f"âŒ íŠ¸ë¦¬ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise

    def _print_tree_summary(self, nodes: List[StoryNode]):
        """ìƒì„±ëœ íŠ¸ë¦¬ êµ¬ì¡° ìš”ì•½ ì¶œë ¥"""
        if not nodes:
            return

        depth_counts = {}
        for node in nodes:
            depth = node.get("depth", 0)
            depth_counts[depth] = depth_counts.get(depth, 0) + 1

        print("\nğŸ“ˆ íŠ¸ë¦¬ êµ¬ì¡° ìš”ì•½:")
        for depth in sorted(depth_counts.keys()):
            count = depth_counts[depth]
            indent = "  " * depth
            print(f"  {indent}ê¹Šì´ {depth}: {count}ê°œ ë…¸ë“œ")

    # --- LangGraph ë‚´ë¶€ ë¡œì§ (Worker) ---
    async def _node_generator(self, state: Dict):
        """ì‹¤ì œ LLMì„ í˜¸ì¶œí•˜ì—¬ ìŠ¤í† ë¦¬ ë…¸ë“œë¥¼ ìƒì„±í•˜ëŠ” ì›Œì»¤"""

        # Sendë¡œ ì „ë‹¬ëœ task ì •ë³´ ë˜ëŠ” ì´ˆê¸° ìƒíƒœì—ì„œ ì¶”ì¶œ
        if "task" in state:
            task = state["task"]
            depth = task["depth"]
            parent = task.get("parent_node")
            choice_taken = task.get("choice_taken")
            context = state["context"]
        else:
            # ì´ˆê¸° ë£¨íŠ¸ ë…¸ë“œ ìƒì„±
            depth = 0
            parent = None
            choice_taken = None
            context = state["context"]

        # ë…¸ë“œ íƒ€ì… ê²°ì • (AIê°€ ì„ íƒì§€ ê°œìˆ˜ëŠ” ìë™ íŒë‹¨)
        max_depth = state.get("max_depth", 5)
        if depth == max_depth:
            node_type = "ending"
        elif depth == 0:
            node_type = "first_choice"
        elif depth == max_depth - 1:
            node_type = "climax"
        else:
            node_type = "development"

        # ìºë¦­í„° ì •ë³´ í¬ë§·íŒ…
        characters_info = self._format_characters(context.get("characters", []))

        # ê²Œì´ì§€ ì •ë³´ í¬ë§·íŒ…
        gauges_info = self._format_gauges(context.get("gauges", []))

        # ì—”ë”© ì •ë³´ í¬ë§·íŒ…
        endings_info = self._format_endings(context.get("endings", []))

        # ì´ì „ ìŠ¤í† ë¦¬ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        previous_context = ""
        if parent:
            previous_context = f"\n[ì´ì „ ìŠ¤í† ë¦¬]\n{parent.get('text', '')}\n\n[í”Œë ˆì´ì–´ì˜ ì„ íƒ]\n{choice_taken.get('text', '') if choice_taken else '(ì‹œì‘)'}"

        # í˜„ì¬ ê²Œì´ì§€ ìƒíƒœ ê³„ì‚°
        current_gauges = self._calculate_current_gauges(state, choice_taken)

        system_prompt = f"""ë‹¹ì‹ ì€ ì¸í„°ë™í‹°ë¸Œ ì†Œì„¤ ì‘ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìŠ¤í† ë¦¬ ë…¸ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

[ì†Œì„¤ ë°°ê²½]
{context.get('novel_summary', 'ì •ë³´ ì—†ìŒ')}

[ë“±ì¥ì¸ë¬¼]
{characters_info}

[ê²Œì´ì§€ ì‹œìŠ¤í…œ]
{gauges_info}

[í˜„ì¬ ê²Œì´ì§€ ìƒíƒœ]
{json.dumps(current_gauges, ensure_ascii=False)}

[ê°€ëŠ¥í•œ ì—”ë”©ë“¤]
{endings_info}

[í˜„ì¬ ë…¸ë“œ ì •ë³´]
- ê¹Šì´: {depth}/{max_depth}
- ë…¸ë“œ íƒ€ì…: {node_type}
- ì„ íƒì§€ ê°œìˆ˜: ìƒí™©ì— ë§ê²Œ 2~4ê°œ ì¤‘ ìë™ ê²°ì •

{previous_context}"""

        user_prompt = f"""ìœ„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ìŠ¤í† ë¦¬ ë…¸ë“œë¥¼ ìƒì„±í•˜ì„¸ìš”.

[ì‘ì„± ìš”êµ¬ì‚¬í•­]
1. **ìŠ¤í† ë¦¬ ë³¸ë¬¸** (1200-2000ì) - ë…ìê°€ ì™„ì „íˆ ëª°ì…í•  ìˆ˜ ìˆë„ë¡ ì‘ì„±:

   ğŸ¬ **ì˜í™”ì  ì¥ë©´ ë¬˜ì‚¬** (í•„ìˆ˜):
   - ì‹œê°ì  ë””í…Œì¼: ìºë¦­í„°ì˜ í‘œì •, ëª¸ì§“, ì£¼ë³€ í™˜ê²½ì˜ ìƒ‰ê°ê³¼ ë¹›
   - ì²­ê°ì  ìš”ì†Œ: ëŒ€í™” í†¤, ë°°ê²½ ì†Œë¦¬, ì¹¨ë¬µì˜ ë¬´ê²Œê°
   - ì´‰ê°/í›„ê°: ê¸´ì¥ê°ì´ ëŠê»´ì§€ëŠ” ë¶„ìœ„ê¸°, ê³µê°„ì˜ ì˜¨ë„ê°

   ğŸ’­ **ë‚´ì  ë…ë°±** (í•„ìˆ˜):
   - ì£¼ìš” ìºë¦­í„°ì˜ ì§„ì§œ ìƒê°ê³¼ ê°ì •ì„ ê¹Šì´ ìˆê²Œ í‘œí˜„
   - í‘œë©´ì ìœ¼ë¡œ ë³´ì´ëŠ” ê²ƒê³¼ ë‚´ë©´ì˜ ê°ˆë“± ëŒ€ì¡°
   - ê³¼ê±° ê¸°ì–µì´ë‚˜ ë‘ë ¤ì›€ì´ í˜„ì¬ì— ë¯¸ì¹˜ëŠ” ì˜í–¥

   ğŸ—£ï¸ **ìƒìƒí•œ ëŒ€í™”** (ìµœì†Œ 2-3íšŒ êµí™˜):
   - ìºë¦­í„° ì„±ê²©ì´ ë“œëŸ¬ë‚˜ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”
   - ëŒ€í™” ì¤‘ í‘œì •, ëª¸ì§“, ë§íˆ¬ ë³€í™” ë¬˜ì‚¬
   - ë§í•˜ì§€ ì•Šì€ ê²ƒ(ì¹¨ë¬µ, ë§ì„¤ì„)ë„ ì˜ë¯¸ ìˆê²Œ í‘œí˜„

   â±ï¸ **ì‹œê°„ì˜ íë¦„ê³¼ í…œí¬**:
   - ê¸´ë°•í•œ ìˆœê°„ì€ ì§§ê³  ê°•ë ¬í•˜ê²Œ
   - ì¤‘ìš”í•œ ê°ì • ìˆœê°„ì€ ëŠë¦¬ê³  ì„¬ì„¸í•˜ê²Œ

   ì˜ˆì‹œ ìŠ¤íƒ€ì¼:
   "ë í”„ëŠ” ì†ì— ì¥” ì†Œë¼ê»ë°ê¸°ë¥¼ ë‚´ë ¤ë‹¤ë´¤ë‹¤. í–‡ë¹›ì— ë°˜ì§ì´ëŠ” í‘œë©´ì´ ë§ˆì¹˜ í¬ë§ì˜ ìƒì§•ì²˜ëŸ¼ ëŠê»´ì¡Œë‹¤.
   í•˜ì§€ë§Œ ê°€ìŠ´ ê¹Šì€ ê³³ì—ì„œëŠ” ë¶ˆì•ˆì´ ê¿ˆí‹€ê±°ë ¸ë‹¤. 'ì •ë§ ìš°ë¦¬ë¥¼ êµ¬í•˜ëŸ¬ ì˜¬ê¹Œ?'

   'ë´‰í™”ë¥¼ í”¼ì›Œì•¼ í•´.' ë í”„ê°€ ë§í–ˆë‹¤. ëª©ì†Œë¦¬ëŠ” ì˜ë„ì ìœ¼ë¡œ ë‹¨í˜¸í•˜ê²Œ ë§Œë“¤ì—ˆì§€ë§Œ,
   ì†ì€ ë¯¸ì„¸í•˜ê²Œ ë–¨ë¦¬ê³  ìˆì—ˆë‹¤. ë‹¤ë¥¸ ì•„ì´ë“¤ì´ ì•Œì•„ì±Œê¹Œ ë´ ì¬ë¹¨ë¦¬ ì£¼ë¨¹ì„ ì¥ì—ˆë‹¤.

   ì­ì´ ë¹„ì›ƒìŒì„ í˜ë ¸ë‹¤. 'êµ¬ì¡°?' ê·¸ê°€ ë‚ ì¹´ë¡­ê²Œ ì›ƒìœ¼ë©° ê³ ê°œë¥¼ ì €ì—ˆë‹¤. 'ê·¸ê²Œ ì¤‘ìš”í•œ ê²Œ ì•„ë‹ˆì•¼.
   ì§€ê¸ˆ ë‹¹ì¥ ë¨¹ì„ ê³ ê¸°ê°€ í•„ìš”í•˜ë‹¤ê³ !' ê·¸ì˜ ëˆˆì—ëŠ” ì•¼ì„±ì ì¸ í¥ë¶„ì´ íƒ€ì˜¤ë¥´ê³  ìˆì—ˆë‹¤.
   ì‚¬ëƒ¥ì˜ ì¾Œê°ì´ ì´ì„±ì„ ì§‘ì–´ì‚¼í‚¤ê¸° ì‹œì‘í•œ ê²ƒ ê°™ì•˜ë‹¤.

   ë‘ ì†Œë…„ ì‚¬ì´ì˜ ê³µê¸°ê°€ íŒ½íŒ½í•˜ê²Œ ê¸´ì¥í–ˆë‹¤. ë‹¤ë¥¸ ì•„ì´ë“¤ì€ ìˆ¨ì„ ì£½ì´ê³  ì§€ì¼œë´¤ë‹¤..."

2. **ë””í…Œì¼ ì •ë³´**:
   - npc_emotions: í˜„ì¬ ë“±ì¥í•˜ëŠ” NPCë“¤ì˜ ê°ì • ìƒíƒœ (ì˜ˆ: {{'ë í”„': 'ë¶ˆì•ˆ', 'ì­': 'í¥ë¶„'}})
   - situation: í˜„ì¬ ìƒí™© í•œ ì¤„ ìš”ì•½
   - relations_update: ì´ë²ˆ ì¥ë©´ìœ¼ë¡œ ì¸í•œ ì¸ë¬¼ ê´€ê³„ ë³€í™” (ì˜ˆ: {{'ë í”„-ì­': 'ì ëŒ€ê° ìƒìŠ¹'}})

3. **ì„ íƒì§€** (2~4ê°œ, ìƒí™©ì— ë§ê²Œ íŒë‹¨):
   - ì„ íƒì§€ ê°œìˆ˜ëŠ” í˜„ì¬ ìƒí™©ì˜ ë³µì¡ë„ì™€ ì¤‘ìš”ë„ì— ë”°ë¼ 2~4ê°œ ì¤‘ ì ì ˆíˆ ê²°ì •í•˜ì„¸ìš”
     - ë‹¨ìˆœí•œ ìƒí™©, ê¸´ë°•í•œ ìˆœê°„: 2ê°œ
     - ì¼ë°˜ì ì¸ ìƒí™©: 3ê°œ
     - ì¤‘ìš”í•œ ë¶„ê¸°ì , ë‹¤ì–‘í•œ ì ‘ê·¼ì´ ê°€ëŠ¥í•œ ìƒí™©: 4ê°œ
   - ì„ íƒì§€ í…ìŠ¤íŠ¸ëŠ” í”Œë ˆì´ì–´ ê´€ì ì—ì„œ 1ì¸ì¹­ìœ¼ë¡œ ì‘ì„±í•˜ë˜, ì„ íƒì˜ ê°ì •ì  ë¬´ê²Œê°ì„ í‘œí˜„
   - ì„ íƒì˜ ë‹¨ê¸°ì  ê²°ê³¼ë¥¼ ì•”ì‹œí•˜ëŠ” ë¬˜ì‚¬ í¬í•¨ (ì˜ˆ: "í•˜ì§€ë§Œ ê·¸ì˜ ëˆˆë¹›ì—ì„œ ìœ„í˜‘ì„ ëŠë‚€ë‹¤")
   - ê° ì„ íƒì§€ì— íŠ¹ì„± íƒœê·¸ í¬í•¨ (1~2ê°œì”©)
   - ì‚¬ìš© ê°€ëŠ¥í•œ íƒœê·¸: cooperative, aggressive, cautious, trusting, doubtful, brave, fearful, rational, emotional

   ğŸ­ **ì¦‰ê° ë°˜ì‘ (immediate_reaction)** - âš ï¸ ëª¨ë“  ì„ íƒì§€ë§ˆë‹¤ MANDATORY í•„ìˆ˜ ì‘ì„± (100-200ì):
   - í”Œë ˆì´ì–´ê°€ ì´ ì„ íƒì„ í–ˆì„ ë•Œ **ì¦‰ì‹œ** ë²Œì–´ì§€ëŠ” ì¼
   - ìºë¦­í„°ë“¤ì˜ ì²« ë°˜ì‘ (í‘œì •, ëª¸ì§“, ì§§ì€ ë§)
   - ë¶„ìœ„ê¸°ì˜ ë³€í™” (ê¸´ì¥ê° ìƒìŠ¹/í•˜ê°•, ì˜¨ë„ê° ë³€í™”)
   - í”Œë ˆì´ì–´ì˜ ë‚´ì  ê°ì • (í›„íšŒ, í™•ì‹ , ë¶ˆì•ˆ ë“±)
   - ë‹¤ìŒ ì¥ë©´ìœ¼ë¡œ ë„˜ì–´ê°€ê¸° ì „ ì§§ì€ "ìˆ¨ê³ ë¥´ê¸°" ì œê³µ

   âš ï¸ CRITICAL: immediate_reactionì´ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìœ¼ë©´ ì ˆëŒ€ ì•ˆ ë©ë‹ˆë‹¤! ë°˜ë“œì‹œ ê° ì„ íƒì§€ë§ˆë‹¤ 100ì ì´ìƒìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”!

   ì˜ˆì‹œ 1 (í˜‘ë ¥ì  ì„ íƒ):
   "ë‹¹ì‹ ì´ ì†ì„ ë‚´ë°€ì ê·¸ì˜ ê²½ê³„ì‹¬ì´ ì¡°ê¸ˆ í’€ë¦¬ëŠ” ê²ƒì´ ë³´ì˜€ë‹¤. 'ë¯¿ì–´ë„ ë˜ëŠ” ê±¸ê¹Œ?' ê·¸ê°€ ë‚®ê²Œ ì¤‘ì–¼ê±°ë ¸ë‹¤.
   ì£¼ë³€ ì‚¬ëŒë“¤ì˜ ì‹œì„ ì´ ë‹¹ì‹ ì—ê²Œ ì§‘ì¤‘ë˜ì—ˆê³ , ê³µê¸° ì¤‘ì˜ ê¸´ì¥ê°ì´ ë¯¸ë¬˜í•˜ê²Œ ì™„í™”ë˜ëŠ” ëŠë‚Œì´ ë“¤ì—ˆë‹¤."

   ì˜ˆì‹œ 2 (ê³µê²©ì  ì„ íƒ):
   "ë‹¹ì‹ ì˜ ë‚ ì¹´ë¡œìš´ ë§ì— ê·¸ì˜ í‘œì •ì´ êµ³ì–´ì¡Œë‹¤. ì£¼ë¨¹ì„ ë¶ˆëˆ ì¥” ê·¸ê°€ í•œ ë°œì§ ë‹¤ê°€ì„°ë‹¤.
   ì£¼ë³€ ê³µê¸°ê°€ ì–¼ì–´ë¶™ì—ˆê³ , ë‹¹ì‹ ì€ ì´ ì„ íƒì´ ëŒì´í‚¬ ìˆ˜ ì—†ëŠ” ê°ˆë“±ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ì§ê°í–ˆë‹¤."

{"âš ï¸ ì´ê²ƒì€ ì—í”¼ì†Œë“œ ì—”ë”©ìœ¼ë¡œ ì—°ê²°ë˜ëŠ” ë…¸ë“œì…ë‹ˆë‹¤. ìŠ¤í† ë¦¬ë¥¼ ì ì ˆíˆ ë§ˆë¬´ë¦¬í•˜ê³  ì„ íƒì§€ëŠ” ë¹ˆ ë°°ì—´ë¡œ ë‘ì„¸ìš”." if node_type == "ending" else ""}

âš ï¸ CRITICAL: ëª¨ë“  ì„ íƒì§€ì— immediate_reactionì„ 100-200ìë¡œ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”!

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "text": "ìŠ¤í† ë¦¬ ë³¸ë¬¸ (1200-2000ì)...",
    "details": {{
        "npc_emotions": {{"ìºë¦­í„°ëª…": "ê°ì •"}},
        "situation": "ìƒí™© ìš”ì•½",
        "relations_update": {{ "ê´€ê³„": "ë³€í™” ë‚´ìš©" }}
    }},
    "choices": [
        {{
            "text": "ê·¸ì—ê²Œ ì†ì„ ë‚´ë°€ë©° í˜‘ë ¥ì„ ì œì•ˆí•œë‹¤",
            "tags": ["cooperative", "trusting"],
            "immediate_reaction": "ë‹¹ì‹ ì´ ì†ì„ ë‚´ë°€ì ê·¸ì˜ ëˆˆë¹›ì´ ì ì‹œ í”ë“¤ë ¸ë‹¤. 'ì •ë§... ë¯¿ì–´ë„ ë˜ëŠ” ê±´ê°€?' ê·¸ê°€ ì¡°ì‹¬ìŠ¤ëŸ½ê²Œ ë‹¹ì‹ ì˜ ì†ì„ ë°”ë¼ë³´ì•˜ë‹¤. ì£¼ë³€ ì‚¬ëŒë“¤ì˜ ìˆ¨ì†Œë¦¬ê°€ ë©ˆì¶˜ ë“¯ ê³ ìš”í–ˆê³ , ê³µê¸° ì¤‘ì˜ ê¸´ì¥ê°ì´ ë¯¸ë¬˜í•˜ê²Œ í’€ë¦¬ëŠ” ê²ƒì„ ëŠë‚„ ìˆ˜ ìˆì—ˆë‹¤."
        }},
        {{
            "text": "ê·¸ì˜ ì•½ì ì„ ì§€ì í•˜ë©° ì••ë°•í•œë‹¤",
            "tags": ["aggressive", "rational"],
            "immediate_reaction": "ë‹¹ì‹ ì˜ ë‚ ì¹´ë¡œìš´ ì§€ì ì— ê·¸ì˜ ì–¼êµ´ì´ ì°½ë°±í•´ì¡Œë‹¤. ì£¼ë¨¹ì„ ë¶ˆëˆ ì¥” ê·¸ê°€ ì´ë¥¼ ì•…ë¬¼ì—ˆë‹¤. 'ì´ ìì‹ì´...' ê·¸ê°€ ë‚®ê²Œ ì¤‘ì–¼ê±°ë ¸ê³ , ì£¼ë³€ ê³µê¸°ê°€ í•œìˆœê°„ ì–¼ì–´ë¶™ì—ˆë‹¤. ë‹¹ì‹ ì€ ëŒì´í‚¬ ìˆ˜ ì—†ëŠ” ì„ ì„ ë„˜ì—ˆë‹¤ëŠ” ê²ƒì„ ì§ê°í–ˆë‹¤."
        }},
        {{
            "text": "ì„¸ ë²ˆì§¸ ì„ íƒì§€ ì˜ˆì‹œ",
            "tags": ["cautious", "emotional"],
            "immediate_reaction": "âš ï¸ ëª¨ë“  ì„ íƒì§€ì— immediate_reaction í•„ë“œê°€ ë°˜ë“œì‹œ ìˆì–´ì•¼ í•©ë‹ˆë‹¤! ì ˆëŒ€ ë¹ ëœ¨ë¦¬ì§€ ë§ˆì„¸ìš”!"
        }}
    ]
}}

âš ï¸âš ï¸âš ï¸ ì¤‘ìš”: ìœ„ JSONì˜ ëª¨ë“  choice ê°ì²´ì— immediate_reaction í•„ë“œê°€ ìˆëŠ” ê²ƒì„ í™•ì¸í•˜ì„¸ìš”!
ì„ íƒì§€ê°€ 2ê°œë“  3ê°œë“  4ê°œë“ , ëª¨ë“  ì„ íƒì§€ë§ˆë‹¤ immediate_reactionì„ ë°˜ë“œì‹œ ì‘ì„±í•˜ì„¸ìš”!

âš ï¸ ë‹¤ì‹œ í•œë²ˆ ê°•ì¡°: immediate_reaction í•„ë“œë¥¼ ì ˆëŒ€ ë¹ ëœ¨ë¦¬ì§€ ë§ˆì„¸ìš”! ê° ì„ íƒë§ˆë‹¤ 100ì ì´ìƒ í•„ìˆ˜ì…ë‹ˆë‹¤!"""

        try:
            # Structured Output ëª¨ë“œë¡œ LLM í˜¸ì¶œ (JSON Schema ê°•ì œ)
            print("  ğŸ”§ Structured Output ëª¨ë“œë¡œ ë…¸ë“œ ìƒì„± ì¤‘...")
            structured_response = await self.structured_llm.ainvoke([
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt)
            ])

            # Pydantic ëª¨ë¸ì´ ìë™ìœ¼ë¡œ ê²€ì¦í•˜ë¯€ë¡œ immediate_reactionì´ ë³´ì¥ë¨
            print(f"ğŸ” DEBUG - Structured Output ì‘ë‹µ:")
            print(f"  ì„ íƒì§€ ê°œìˆ˜: {len(structured_response.choices)}")
            for idx, choice in enumerate(structured_response.choices):
                print(f"  Choice {idx+1}: immediate_reaction ê¸¸ì´ = {len(choice.immediate_reaction)}ì")
                print(f"    ë‚´ìš©: {choice.immediate_reaction[:100]}...")

            # Pydantic ëª¨ë¸ì„ dictë¡œ ë³€í™˜
            parsed = structured_response.model_dump()

            # ë…¸ë“œ ID ìƒì„±
            node_id = str(uuid.uuid4())[:8]

            # ë…¸ë“œ êµ¬ì„±
            new_node: StoryNode = {
                "id": node_id,
                "depth": depth,
                "text": parsed.get("text", "ìŠ¤í† ë¦¬ ìƒì„± ì‹¤íŒ¨"),
                "details": parsed.get("details", {
                    "npc_emotions": {},
                    "situation": "ì•Œ ìˆ˜ ì—†ìŒ",
                    "relations_update": {}
                }),
                "choices": parsed.get("choices", []),
                "parent_id": parent["id"] if parent else None,
                "node_type": node_type,
                "episode_id": context.get("episode_id", "unknown")
            }

            print(f"  âœ… ë…¸ë“œ ìƒì„± ì™„ë£Œ: depth={depth}, id={node_id}, choices={len(new_node['choices'])}")

            return {"nodes": [new_node], "current_gauges": current_gauges}

        except Exception as e:
            print(f"  âŒ ë…¸ë“œ ìƒì„± ì‹¤íŒ¨ (depth={depth}): {e}")
            # í´ë°± ë…¸ë“œ ìƒì„±
            fallback_node: StoryNode = {
                "id": str(uuid.uuid4())[:8],
                "depth": depth,
                "text": f"[ì˜¤ë¥˜ë¡œ ì¸í•´ ìŠ¤í† ë¦¬ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}]",
                "details": {
                    "npc_emotions": {},
                    "situation": "ì˜¤ë¥˜ ë°œìƒ",
                    "relations_update": {}
                },
                "choices": [],
                "parent_id": parent["id"] if parent else None,
                "node_type": "error",
                "episode_id": context.get("episode_id", "unknown")
            }
            return {"nodes": [fallback_node], "current_gauges": current_gauges}

    def _format_characters(self, characters: List[Character]) -> str:
        """ìºë¦­í„° ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ìš© ë¬¸ìì—´ë¡œ í¬ë§·íŒ…"""
        if not characters:
            return "ë“±ë¡ëœ ìºë¦­í„° ì—†ìŒ"

        result = []
        for char in characters:
            # cite íƒœê·¸ ì œê±°í•˜ì—¬ í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš© (ê°„ê²°í•˜ê²Œ)
            description = char.get('description', 'ì •ë³´ ì—†ìŒ')
            # [cite: ...] íŒ¨í„´ ì œê±°
            import re
            clean_desc = re.sub(r'\\\[cite:.*?\\\\]', '', description).strip()
            # ë„ˆë¬´ ê¸¸ë©´ ì¤„ì„
            if len(clean_desc) > 300:
                clean_desc = clean_desc[:300] + "..."

            char_info = f"""â€¢ {char.get('name', 'ì´ë¦„ì—†ìŒ')} (ë³„ëª…: {', '.join(char.get('aliases', []))})
  - ì„¤ëª…: {clean_desc}
  - ê´€ê³„: {'; '.join(char.get('relationships', [])[:3])}"""
            result.append(char_info)

        return "\n".join(result)

    def _format_gauges(self, gauges: List[Gauge]) -> str:
        """ê²Œì´ì§€ ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ìš© ë¬¸ìì—´ë¡œ í¬ë§·íŒ…"""
        if not gauges:
            return "ë“±ë¡ëœ ê²Œì´ì§€ ì—†ìŒ"

        result = []
        for g in gauges:
            gauge_info = f"""â€¢ {g.get('name', 'ì´ë¦„ì—†ìŒ')} (id: {g.get('id', 'unknown')})
  - ì˜ë¯¸: {g.get('meaning', 'ë¶ˆëª…')}
  - 0: {g.get('min_label', 'ìµœì†Œ')} â†” 100: {g.get('max_label', 'ìµœëŒ€')}"""
            result.append(gauge_info)

        return "\n".join(result)

    def _format_endings(self, endings: List[FinalEnding]) -> str:
        """ì—”ë”© ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ìš© ë¬¸ìì—´ë¡œ í¬ë§·íŒ…"""
        if not endings:
            return "ë“±ë¡ëœ ì—”ë”© ì—†ìŒ"

        result = []
        for e in endings:
            ending_info = f"""â€¢ [{e.get('type', 'unknown')}] {e.get('title', 'ì œëª©ì—†ìŒ')}
  - ì¡°ê±´: {e.get('condition', 'ë¶ˆëª…')}"""
            result.append(ending_info)

        return "\n".join(result)

    def _calculate_current_gauges(self, state: Dict, choice_taken: Optional[StoryChoice]) -> Dict[str, int]:
        """í˜„ì¬ ê²Œì´ì§€ ìƒíƒœ ê³„ì‚°"""
        # ì´ˆê¸°ê°’ ì„¤ì • (ëª¨ë“  ê²Œì´ì§€ 50ì—ì„œ ì‹œì‘)
        current = state.get("current_gauges", {})
        if not current:
            for g in state.get("context", {}).get("gauges", []):
                current[g.get("id", g.get("name", "unknown"))] = 50
        else:
            current = current.copy()

        # ì„ íƒì— ë”°ë¥¸ ê²Œì´ì§€ ë³€í™” ì ìš©
        if choice_taken and "gauge_changes" in choice_taken:
            for gauge_id, change in choice_taken["gauge_changes"].items():
                if gauge_id in current:
                    current[gauge_id] = max(0, min(100, current[gauge_id] + change))
                else:
                    current[gauge_id] = max(0, min(100, 50 + change))

        return current

    # --- LangGraph ë‚´ë¶€ ë¡œì§ (Manager) ---
    def _plan_next_step(self, state):
        """
        Map-Reduce íŒ¨í„´ì„ ì‚¬ìš©í•œ íŠ¸ë¦¬ ë¶„ê¸° ë¡œì§

        - ê° ë…¸ë“œì˜ ì„ íƒì§€ë§ˆë‹¤ ìƒˆë¡œìš´ ìì‹ ë…¸ë“œë¥¼ ìƒì„±
        - ìµœëŒ€ ê¹Šì´ì— ë„ë‹¬í•˜ë©´ ì¢…ë£Œ
        - ì„ íƒì§€ê°€ ì—†ëŠ” ë…¸ë“œ(ì—”ë”©)ëŠ” ë” ì´ìƒ ë¶„ê¸°í•˜ì§€ ì•ŠìŒ
        """
        nodes = state.get("nodes", [])
        max_depth = state.get("max_depth", 5)
        context = state.get("context", {})
        current_gauges = state.get("current_gauges", {})

        # ì•„ì§ ë…¸ë“œê°€ ì—†ìœ¼ë©´ ë£¨íŠ¸ ë…¸ë“œ ìƒì„±ì„ ìœ„í•´ ì´ˆê¸° ìƒíƒœ ë°˜í™˜
        if not nodes:
            return [Send("generate_node", {
                "context": context,
                "max_depth": max_depth,
                "current_gauges": current_gauges
            })]

        # ê°€ì¥ ìµœê·¼ì— ìƒì„±ëœ ë…¸ë“œë“¤ ì°¾ê¸° (ê°™ì€ ê¹Šì´ì˜ ë…¸ë“œë“¤)
        # LangGraphì˜ Map-Reduceì—ì„œëŠ” ë³‘ë ¬ë¡œ ìƒì„±ëœ ë…¸ë“œë“¤ì´ í•œ ë²ˆì— ì¶”ê°€ë¨
        if len(nodes) == 1:
            latest_nodes = nodes
        else:
            # ê°€ì¥ ê¹Šì€ depthì˜ ë…¸ë“œë“¤ì„ ì°¾ìŒ
            max_current_depth = max(n["depth"] for n in nodes)
            latest_nodes = [n for n in nodes if n["depth"] == max_current_depth]

        # ìµœëŒ€ ê¹Šì´ ì²´í¬
        if latest_nodes and latest_nodes[0]["depth"] > max_depth:
            print(f"ğŸ ìµœëŒ€ ê¹Šì´ {max_depth} ë„ë‹¬. íŠ¸ë¦¬ ìƒì„± ì™„ë£Œ.")
            return END

        # ê° ìµœì‹  ë…¸ë“œì˜ ì„ íƒì§€ì— ëŒ€í•´ ìì‹ ë…¸ë“œ ìƒì„± íƒœìŠ¤í¬ ìƒì„±
        tasks = []
        for node in latest_nodes:
            choices = node.get("choices", [])

            if not choices:
                # ì„ íƒì§€ê°€ ì—†ëŠ” ë…¸ë“œ (ì—”ë”© ë˜ëŠ” ì—ëŸ¬)ëŠ” ìŠ¤í‚µ
                continue

            for choice_idx, choice in enumerate(choices):
                # ì´ ì„ íƒì§€ë¥¼ ì„ íƒí–ˆì„ ë•Œì˜ ìì‹ ë…¸ë“œ ìƒì„± íƒœìŠ¤í¬
                task = {
                    "task": {
                        "depth": node["depth"] + 1,
                        "parent_node": node,
                        "choice_taken": choice,
                        "choice_index": choice_idx
                    },
                    "context": context,
                    "max_depth": max_depth,
                    "current_gauges": current_gauges
                }
                tasks.append(Send("generate_node", task))
                print(f"  ğŸ“ íƒœìŠ¤í¬ ì˜ˆì•½: depth={node['depth']+1}, parent={node['id']}, choice={choice_idx}")

        if not tasks:
            print("ğŸ ë” ì´ìƒ ìƒì„±í•  ë…¸ë“œê°€ ì—†ìŠµë‹ˆë‹¤. íŠ¸ë¦¬ ìƒì„± ì™„ë£Œ.")
            return END

        print(f"ğŸ”€ {len(tasks)}ê°œì˜ ë¶„ê¸° ë…¸ë“œ ìƒì„± ì‹œì‘...")
        return tasks

    # ìœ í‹¸ë¦¬í‹°
    def _parse_json(self, content: str) -> Dict:
        """LLM ì‘ë‹µì—ì„œ JSONì„ ì•ˆì „í•˜ê²Œ íŒŒì‹±"""
        try:
            # ë¨¼ì € LangChain íŒŒì„œ ì‹œë„
            return self.json_parser.parse(content)
        except Exception:
            pass

        # ì§ì ‘ JSON ì¶”ì¶œ ì‹œë„
        try:
            # ```json ... ``` ë¸”ë¡ ì¶”ì¶œ
            json_match = re.search(r'```(?:json)?\s*([\s\S]*?)\s*```', content)
            if json_match:
                json_str = json_match.group(1).strip()
                return json.loads(json_str)

            # { } ë¸”ë¡ ì§ì ‘ ì¶”ì¶œ (ê°€ì¥ í° JSON ê°ì²´ ì°¾ê¸°)
            json_match = re.search(r'\{[\s\S]*\}', content)
            if json_match:
                json_str = json_match.group(0).strip()
                return json.loads(json_str)

            # ì§ì ‘ íŒŒì‹± ì‹œë„
            return json.loads(content.strip())

        except json.JSONDecodeError as e:
            print(f"  âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            # ë””ë²„ê¹…ì„ ìœ„í•´ ì‘ë‹µì˜ ì „ì²´ ì¶œë ¥ (ìµœëŒ€ 2000ì)
            preview = content[:2000] if len(content) > 2000 else content
            print(f"  ğŸ“„ ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: ```json\n{preview}\n```")

            # ì¼ë°˜ì ì¸ JSON ì˜¤ë¥˜ ìë™ ìˆ˜ì • ì‹œë„
            print("  ğŸ”§ ìë™ ìˆ˜ì • ì‹œë„ ì¤‘...")
            try:
                fixed_content = content

                # 1. í›„í–‰ ì‰¼í‘œ ì œê±° (ê°ì²´, ë°°ì—´ ëª¨ë‘)
                fixed_content = re.sub(r',(\s*[}\]])', r'\1', fixed_content)

                # 2. ì—¬ëŸ¬ ì‰¼í‘œ ì—°ì†ì„ í•˜ë‚˜ë¡œ
                fixed_content = re.sub(r',\s*,+', ',', fixed_content)

                # 3. ì¤„ë°”ê¿ˆ/ê³µë°±ì´ ìˆëŠ” í›„í–‰ ì‰¼í‘œë„ ì œê±°
                fixed_content = re.sub(r',\s*\n\s*}', '}', fixed_content)
                fixed_content = re.sub(r',\s*\n\s*]', ']', fixed_content)

                # 4. JSON ë¸”ë¡ ì¶”ì¶œ
                json_match = re.search(r'\{[\s\S]*\}', fixed_content)
                if json_match:
                    cleaned = json_match.group(0)
                    print(f"  âœ… ìˆ˜ì •ëœ JSON ê¸¸ì´: {len(cleaned)} chars")
                    result = json.loads(cleaned)
                    print(f"  âœ… JSON íŒŒì‹± ì„±ê³µ! keys: {result.keys() if isinstance(result, dict) else 'N/A'}")
                    return result
            except Exception as fix_error:
                print(f"  âŒ ìë™ ìˆ˜ì • ì‹¤íŒ¨: {fix_error}")

        return {}

    async def _generate_summary(self, novel_text: str) -> str:
        """ì†Œì„¤ í…ìŠ¤íŠ¸ ìš”ì•½ ìƒì„± - ì²­í¬ ë¶„í•  í›„ í†µí•© ìš”ì•½"""
        chunk_size = 20000  # ê° ì²­í¬ í¬ê¸°

        if len(novel_text) <= chunk_size:
            # ì§§ì€ í…ìŠ¤íŠ¸ëŠ” ë°”ë¡œ ìš”ì•½
            prompt = f"""ë‹¤ìŒ ì†Œì„¤ í…ìŠ¤íŠ¸ë¥¼ 500ì ë‚´ì™¸ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
í•µì‹¬ ì¤„ê±°ë¦¬, ì£¼ì œ, ê°ˆë“± êµ¬ì¡°, ê²°ë§ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.

[ì†Œì„¤ í…ìŠ¤íŠ¸]
{novel_text}
"""
            response = await self.llm.ainvoke(prompt)
            return response.content

        # ê¸´ í…ìŠ¤íŠ¸ëŠ” ì²­í¬ë¡œ ë‚˜ëˆ ì„œ ê°ê° ìš”ì•½
        print(f"  ğŸ“š ê¸´ í…ìŠ¤íŠ¸ ê°ì§€ ({len(novel_text):,}ì), ì²­í¬ ë¶„í•  ìš”ì•½ ì‹œì‘...")

        chunks = []
        for i in range(0, len(novel_text), chunk_size):
            chunks.append(novel_text[i:i + chunk_size])

        print(f"  ğŸ“¦ {len(chunks)}ê°œ ì²­í¬ë¡œ ë¶„í• ")

        # ê° ì²­í¬ ìš”ì•½
        chunk_summaries = []
        for i, chunk in enumerate(chunks):
            print(f"    [{i+1}/{len(chunks)}] ì²­í¬ ìš”ì•½ ì¤‘...")
            prompt = f"""ë‹¤ìŒì€ ì†Œì„¤ì˜ {i+1}ë²ˆì§¸ ë¶€ë¶„ì…ë‹ˆë‹¤. ì´ ë¶€ë¶„ì˜ í•µì‹¬ ë‚´ìš©ì„ 200ì ë‚´ì™¸ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
ì£¼ìš” ì‚¬ê±´, ë“±ì¥ì¸ë¬¼ì˜ í–‰ë™, ê°ˆë“±ì„ í¬í•¨í•˜ì„¸ìš”.

[í…ìŠ¤íŠ¸]
{chunk}
"""
            response = await self.llm.ainvoke(prompt)
            chunk_summaries.append(f"[íŒŒíŠ¸ {i+1}] {response.content}")

        # ì²­í¬ ìš”ì•½ë“¤ì„ í†µí•©í•˜ì—¬ ìµœì¢… ìš”ì•½
        print("  ğŸ”„ ì²­í¬ ìš”ì•½ í†µí•© ì¤‘...")
        combined_summaries = "\n\n".join(chunk_summaries)

        final_prompt = f"""ë‹¤ìŒì€ ì†Œì„¤ì˜ ê° ë¶€ë¶„ë³„ ìš”ì•½ì…ë‹ˆë‹¤. ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ì²´ ì†Œì„¤ì„ 500ì ë‚´ì™¸ë¡œ í†µí•© ìš”ì•½í•´ì£¼ì„¸ìš”.
í•µì‹¬ ì¤„ê±°ë¦¬, ì£¼ì œ, ê°ˆë“± êµ¬ì¡°, ê²°ë§ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.

[ë¶€ë¶„ë³„ ìš”ì•½]
{combined_summaries}
"""
        response = await self.llm.ainvoke(final_prompt)
        print("  âœ… í†µí•© ìš”ì•½ ì™„ë£Œ")

        return response.content


# ==============================================================================
# 3. LangGraph ìƒíƒœ ì •ì˜ (State Definition)
# ==============================================================================

def merge_gauges(current: Dict[str, int], new: Dict[str, int]) -> Dict[str, int]:
    """ê²Œì´ì§€ ìƒíƒœ ë³‘í•© (ìµœì‹  ê°’ìœ¼ë¡œ ì—…ë°ì´íŠ¸)"""
    if not new:
        return current
    result = current.copy() if current else {}
    result.update(new)
    return result

class StoryGenerationState(TypedDict):
    nodes: Annotated[List[StoryNode], operator.add]
    context: Dict[str, Any]  # ìºë¦­í„°, ì†Œì„¤ìš”ì•½, ê²Œì´ì§€, ì—”ë”©, ê°€ì´ë“œ ë“± ëª¨ë“  ì •ë³´
    max_depth: int
    current_gauges: Annotated[Dict[str, int], merge_gauges]  # í˜„ì¬ ê²Œì´ì§€ ìƒíƒœ
