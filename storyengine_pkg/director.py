import json
import operator
import re
import uuid
from typing import TypedDict, List, Dict, Any, Annotated, Optional
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_core.output_parsers import JsonOutputParser
from langgraph.graph import StateGraph, END, START
from langgraph.types import Send

from storyengine_pkg.models import (
    Character,
    Gauge,
    FinalEnding,
    EpisodeEnding,
    Episode,
    StoryNode,
    StoryChoice,
    StoryNodeDetail,
)

# ==============================================================================
# 2. ë©”ì¸ í´ë˜ìŠ¤: ì¸í„°ë™í‹°ë¸Œ ìŠ¤í† ë¦¬ ë””ë ‰í„°
# ==============================================================================

class InteractiveStoryDirector:
    def __init__(self, api_key: str):
        self.llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7, api_key=api_key)
        self.json_parser = JsonOutputParser()

    # --------------------------------------------------------------------------
    # [2ë‹¨ê³„] ë“±ì¥ì¸ë¬¼ ìë™ ì¶”ì¶œ (Extract Characters)
    # --------------------------------------------------------------------------
    async def extract_characters(self, novel_text: str) -> List[Character]:
        print("ğŸ•µï¸ ë“±ì¥ì¸ë¬¼ ë¶„ì„ ì¤‘...")

        # í…ìŠ¤íŠ¸ì— ì¤„ ë²ˆí˜¸ ì¶”ê°€ (cite ì°¸ì¡°ìš©)
        lines = novel_text.split('\n')

        # ì „ì²´ í…ìŠ¤íŠ¸ ì‚¬ìš© (ë„ˆë¬´ ê¸¸ë©´ ì•/ì¤‘ê°„/ë’¤ ìƒ˜í”Œë§)
        if len(lines) <= 1000:
            selected_lines = lines
        else:
            # ì• 400ì¤„, ì¤‘ê°„ 200ì¤„, ë’¤ 400ì¤„
            mid_start = len(lines) // 2 - 100
            selected_lines = lines[:400] + lines[mid_start:mid_start+200] + lines[-400:]

        numbered_text = '\n'.join([f"[{i+1}] {line}" for i, line in enumerate(selected_lines)])

        prompt = f"""ë‹¹ì‹ ì€ ë¬¸í•™ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì†Œì„¤ í…ìŠ¤íŠ¸ì—ì„œ ì£¼ìš” ë“±ì¥ì¸ë¬¼ë“¤ì˜ ì •ë³´ë¥¼ ìƒì„¸íˆ ì¶”ì¶œí•˜ì„¸ìš”.

[ì†Œì„¤ í…ìŠ¤íŠ¸] (ì¤„ ë²ˆí˜¸ í¬í•¨)
{numbered_text}

[ì¶”ì¶œ í•­ëª©]
ê° ìºë¦­í„°ì— ëŒ€í•´ ë‹¤ìŒ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”:

1. **name**: ì´ë¦„
2. **aliases**: ë³„ëª… ë¦¬ìŠ¤íŠ¸ (í…ìŠ¤íŠ¸ì—ì„œ ë¶ˆë¦¬ëŠ” ë‹¤ë¥¸ í˜¸ì¹­ë“¤)
3. **description**: í†µí•© ì„¤ëª… - ë‹¤ìŒì„ ëª¨ë‘ í¬í•¨í•˜ì—¬ ìƒì„¸íˆ ì‘ì„±:
   - ì™¸í˜• ë¬˜ì‚¬ (ë‚˜ì´, ì‹ ì²´ì  íŠ¹ì§•)
   - ì„±ê²© íŠ¹ì„±
   - ì£¼ìš” í–‰ë™ ë° ì‚¬ê±´
   - ìºë¦­í„°ì˜ ë³€í™”/ì„±ì¥
   - ê° ì •ë³´ì˜ ê·¼ê±°ë¥¼ [cite: ì¤„ë²ˆí˜¸] í˜•ì‹ìœ¼ë¡œ í‘œê¸°

4. **relationships**: ë‹¤ë¥¸ ì¸ë¬¼ê³¼ì˜ ê´€ê³„ ë¦¬ìŠ¤íŠ¸
   - ê° ê´€ê³„ë¥¼ êµ¬ì²´ì ì¸ ì‚¬ê±´/ì¥ë©´ê³¼ í•¨ê»˜ ì„¤ëª…
   - [cite: ì¤„ë²ˆí˜¸] í˜•ì‹ìœ¼ë¡œ ê·¼ê±° í‘œê¸°

[ì˜ˆì‹œ]
{{
    "name": "ë í”„",
    "aliases": ["ê¸ˆë°œì˜ ì†Œë…„", "ëŒ€ì¥"],
    "description": "ê¸ˆë°œì˜ ì†Œë…„ìœ¼ë¡œ [cite: 8, 35], ë§Œ 12ì‚´ì…ë‹ˆë‹¤ [cite: 60]. ë”± ë²Œì–´ì§„ ì–´ê¹¨ì™€ ë¶€ë“œëŸ¬ìš´ ëˆˆê°€ë¥¼ ì§€ë…”ìŠµë‹ˆë‹¤ [cite: 61]. ìˆ˜ì˜ì„ ì˜í•˜ë©° [cite: 90] ì†Œë¼ë¥¼ ë¶ˆì–´ ì•„ì´ë“¤ì„ ì†Œì§‘í–ˆìŠµë‹ˆë‹¤ [cite: 131]. íˆ¬í‘œë¥¼ í†µí•´ ëŒ€ì¥ìœ¼ë¡œ ì„ ì¶œë˜ì—ˆìœ¼ë©° [cite: 224], ë´‰í™”ë¥¼ í”¼ì›Œ êµ¬ì¡°ë˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ ì‚¼ìŠµë‹ˆë‹¤ [cite: 436]. ì‚¬ì´ë¨¼ì˜ ì£½ìŒì— ì£„ì±…ê°ì„ ëŠê¼ˆê³  [cite: 2057], êµ¬ì¡° ì§í›„ ìš¸ìŒì„ í„°ëœ¨ë¦½ë‹ˆë‹¤ [cite: 2687].",
    "relationships": [
        "ìƒˆë¼ë¼ì§€ì™€ ì²˜ìŒ ë§Œë‚˜ í•¨ê»˜ í–‰ë™í•¨ [cite: 8-18]",
        "ì­ê³¼ ë¦¬ë”ì‹­ ë¬¸ì œë¡œ ëŒ€ë¦½í•¨ [cite: 612, 892]",
        "ìƒˆë¼ë¼ì§€ì˜ ë³„ëª…ì„ í­ë¡œí–ˆìœ¼ë‚˜ ë‚˜ì¤‘ì—ëŠ” ì‹ ë¢°í•¨ [cite: 215, 1840]"
    ]
}}

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "characters": [
        {{
            "name": "ìºë¦­í„° ì´ë¦„",
            "aliases": ["ë³„ëª…1", "ë³„ëª…2"],
            "description": "ìƒì„¸ ì„¤ëª… [cite: ì¤„ë²ˆí˜¸]...",
            "relationships": ["ê´€ê³„ ì„¤ëª… [cite: ì¤„ë²ˆí˜¸]", ...]
        }}
    ]
}}"""
        response = await self.llm.ainvoke(prompt)
        characters = self._parse_json(response.content).get("characters", [])

        # ë¹ˆ ê²°ê³¼ì¼ ê²½ìš° ê¸°ë³¸ê°’ ë°˜í™˜
        if not characters:
            print("  âš ï¸ ìºë¦­í„° ì¶”ì¶œ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©")
            return [
                {
                    "name": "ì£¼ì¸ê³µ",
                    "aliases": [],
                    "description": "ì£¼ì¸ê³µì— ëŒ€í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "relationships": []
                }
            ]

        return characters

    # --------------------------------------------------------------------------
    # [3ë‹¨ê³„] ê²Œì´ì§€ ì œì•ˆ (Generate Gauges)
    # --------------------------------------------------------------------------
    async def suggest_gauges(self, novel_summary: str) -> List[Gauge]:
        print("ğŸ“Š ìŠ¤í† ë¦¬ ê²Œì´ì§€ ì„¤ê³„ ì¤‘...")
        prompt = f"""ì´ ì†Œì„¤ì˜ í•µì‹¬ ê°ˆë“±ê³¼ í…Œë§ˆë¥¼ ê´€í†µí•˜ëŠ” 'ê²Œì´ì§€(ìˆ˜ì¹˜)' ì‹œìŠ¤í…œì„ ì„¤ê³„í•˜ë ¤ í•©ë‹ˆë‹¤.
ê°€ì¥ ì ì ˆí•œ 5ê°œì˜ ê²Œì´ì§€ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”.

[ì†Œì„¤ ìš”ì•½]
{novel_summary}

[ìš”êµ¬ì‚¬í•­]
ê° ê²Œì´ì§€ì— ëŒ€í•´ ë‹¤ìŒì„ ì •ì˜í•˜ì„¸ìš”:
- id: ì˜ë¬¸ ì†Œë¬¸ì ì‹ë³„ì (ì˜ˆ: "civilization", "fear")
- name: ê²Œì´ì§€ í•œê¸€ ì´ë¦„ (ì˜ˆ: "ë¬¸ëª…ë„", "ê³µí¬ì‹¬")
- meaning: ì´ ê²Œì´ì§€ê°€ ì˜ë¯¸í•˜ëŠ” ë°” (1-2ë¬¸ì¥)
- min_label: 0ì¼ ë•Œì˜ ìƒíƒœ (ì˜ˆ: "ì•¼ë§Œ", "í‰ì˜¨")
- max_label: 100ì¼ ë•Œì˜ ìƒíƒœ (ì˜ˆ: "ì§ˆì„œ", "ê³µí¬")
- description: ìŠ¤í† ë¦¬ì—ì„œ ì´ ê²Œì´ì§€ê°€ ì–´ë–»ê²Œ ì‚¬ìš©ë˜ëŠ”ì§€ ì„¤ëª…
- initial_value: ì†Œì„¤ ì‹œì‘ ì‹œì ì˜ ì´ˆê¸°ê°’ (0~100, ì†Œì„¤ ìƒí™©ì— ë§ê²Œ ì„¤ì •)
  - ì˜ˆ: í‰í™”ë¡œìš´ ì‹œì‘ì´ë©´ hope=70, ìœ„ê¸° ìƒí™©ì´ë©´ hope=30

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "gauges": [
        {{
            "id": "civilization",
            "name": "ë¬¸ëª…ë„",
            "meaning": "ì‚¬íšŒ ì§ˆì„œì™€ ê·œë²”ì„ ìœ ì§€í•˜ë ¤ëŠ” ì •ë„",
            "min_label": "ì•¼ë§Œ",
            "max_label": "ì§ˆì„œ",
            "description": "ë†’ì„ìˆ˜ë¡ ë¯¼ì£¼ì  ë¦¬ë”ì‹­ê³¼ ê·œì¹™ì„ ë”°ë¥´ê³ , ë‚®ì„ìˆ˜ë¡ ë³¸ëŠ¥ê³¼ í­ë ¥ì— ì˜ì¡´",
            "initial_value": 65
        }}
    ]
}}"""
        response = await self.llm.ainvoke(prompt)
        gauges = self._parse_json(response.content).get("gauges", [])

        # ë¹ˆ ê²°ê³¼ì¼ ê²½ìš° ê¸°ë³¸ê°’ ë°˜í™˜
        if not gauges:
            print("  âš ï¸ ê²Œì´ì§€ ì œì•ˆ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©")
            return [
                {
                    "id": "progress",
                    "name": "ì§„í–‰ë„",
                    "meaning": "ìŠ¤í† ë¦¬ ì§„í–‰ ìƒí™©",
                    "min_label": "ì‹œì‘",
                    "max_label": "ì™„ë£Œ",
                    "description": "ìŠ¤í† ë¦¬ê°€ ì–¼ë§ˆë‚˜ ì§„í–‰ë˜ì—ˆëŠ”ì§€ ë‚˜íƒ€ëƒ„"
                }
            ]

        return gauges

    # --------------------------------------------------------------------------
    # [4ë‹¨ê³„] ìµœì¢… ì—”ë”© ìƒì„± (Generate Final Endings - ê²Œì´ì§€ ëˆ„ì  ê¸°ë°˜)
    # --------------------------------------------------------------------------
    async def design_final_endings(
        self,
        novel_summary: str,
        selected_gauges: List[Gauge],
        ending_config: Dict[str, int] = None
    ) -> List[FinalEnding]:
        """
        ìµœì¢… ì—”ë”© ì„¤ê³„

        Args:
            ending_config: ì—”ë”© íƒ€ì…ë³„ ê°œìˆ˜ ì„¤ì •
                ì˜ˆ: {"happy": 2, "tragic": 1, "neutral": 1, "open": 1}
                ì§€ì› íƒ€ì…: happy, tragic, neutral, open, bad, bittersweet
        """
        # ê¸°ë³¸ê°’ ì„¤ì •
        if ending_config is None:
            ending_config = {"happy": 2, "tragic": 1, "neutral": 1, "open": 1}

        total_endings = sum(ending_config.values())
        print(f"ğŸ ìµœì¢… ì—”ë”© ì„¤ê³„ ì¤‘ ({total_endings}ê°œ)...")

        # ê²Œì´ì§€ ì •ë³´ í¬ë§·íŒ…
        gauges_detail = []
        for g in selected_gauges:
            gauge_str = f"â€¢ {g.get('name', '?')} ({g.get('id', '?')}): {g.get('min_label', '?')} (0) â†” {g.get('max_label', '?')} (100)"
            gauges_detail.append(gauge_str)
        gauges_info = "\n".join(gauges_detail)

        # ì—”ë”© íƒ€ì… ìš”êµ¬ì‚¬í•­ ìƒì„±
        ending_requirements = []
        type_descriptions = {
            "happy": "í–‰ë³µí•œ ì—”ë”© (í¬ë§ì ì¸ ê²°ë§, ëª©í‘œ ë‹¬ì„±)",
            "tragic": "ë¹„ê·¹ì ì¸ ì—”ë”© (íŒŒë©¸, ì£½ìŒ, ì‹¤íŒ¨)",
            "neutral": "ì¤‘ë¦½ì ì¸ ì—”ë”© (ë¬´ë‚œí•œ ê²°ë§, í° ë³€í™” ì—†ìŒ)",
            "open": "ì—´ë¦° ê²°ë§ (í•´ì„ì˜ ì—¬ì§€, ë¯¸ì™„ì˜ ì´ì•¼ê¸°)",
            "bad": "ë‚˜ìœ ì—”ë”© (ë¶ˆí–‰í•œ ê²°ë§, ì†ì‹¤)",
            "bittersweet": "ì”ì“¸í•œ ì—”ë”© (í¬ìƒì„ í†µí•œ ì„±ê³µ, ë‹¬ì½¤ì“´ ê²°ë§)"
        }

        for ending_type, count in ending_config.items():
            if count > 0:
                desc = type_descriptions.get(ending_type, ending_type)
                ending_requirements.append(f"- {desc}: {count}ê°œ")

        ending_requirements_str = "\n".join(ending_requirements)

        prompt = f"""ì„ íƒëœ ê²Œì´ì§€ì˜ ìµœì¢… ëˆ„ì  ìˆ˜ì¹˜ì— ë”°ë¼ ë„ë‹¬í•  ìˆ˜ ìˆëŠ” ìµœì¢… ì—”ë”©ì„ ì„¤ê³„í•˜ì„¸ìš”.

[ì†Œì„¤ ìš”ì•½]
{novel_summary}

[ê²Œì´ì§€ ì‹œìŠ¤í…œ]
{gauges_info}

[ì—”ë”© íƒ€ì…ë³„ ìš”êµ¬ì‚¬í•­]
ë‹¤ìŒ íƒ€ì…ê³¼ ê°œìˆ˜ì— ë§ì¶° ì—”ë”©ì„ ìƒì„±í•´ì£¼ì„¸ìš”:
{ending_requirements_str}

ì´ {total_endings}ê°œì˜ ì—”ë”©ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤. 

[ì¤‘ìš”]
- ì´ ì—”ë”©ë“¤ì€ ì—¬ëŸ¬ ì—í”¼ì†Œë“œë¥¼ ê±°ì¹œ í›„ ëˆ„ì ëœ ê²Œì´ì§€ ê°’ìœ¼ë¡œ ê²°ì •ë©ë‹ˆë‹¤.
- ê° ì—í”¼ì†Œë“œ ì—”ë”©ì—ì„œ ê²Œì´ì§€ê°€ +/- ë˜ì–´ ìµœì¢… ê°’ì´ ê²°ì •ë©ë‹ˆë‹¤.
- ê²Œì´ì§€ ì´ˆê¸°ê°’ì€ 50ì´ë©°, 0~100 ë²”ìœ„ì…ë‹ˆë‹¤.

[ìš”êµ¬ì‚¬í•­]
ê° ì—”ë”©ì— ëŒ€í•´ ë‹¤ìŒì„ ì •ì˜í•˜ì„¸ìš”:
- id: ì˜ë¬¸ ì†Œë¬¸ì ì‹ë³„ì (ì˜ˆ: "ending_hope", "ending_despair")
- type: ì—”ë”© íƒ€ì… (ì˜ˆ: "happy", "bad", "neutral", "tragic", "open")
- title: ì—”ë”© ì œëª© (ì˜ˆ: "êµ¬ì¡°ì˜ í¬ë§", "ì•¼ë§Œìœ¼ë¡œì˜ ì¶”ë½")
- condition: ë„ë‹¬ ì¡°ê±´ - ìµœì¢… ê²Œì´ì§€ ìƒíƒœ (ì˜ˆ: "hope >= 70 AND despair <= 30")
- summary: ì—”ë”© ë‚´ìš© ìš”ì•½ (3-5ë¬¸ì¥)

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "endings": [
        {{
            "id": "ending_hope",
            "type": "happy",
            "title": "êµ¬ì¡°ì˜ í¬ë§",
            "condition": "hope >= 70 AND trust >= 60",
            "summary": "ì†Œë…„ë“¤ì€ ëê¹Œì§€ í¬ë§ì„ ìƒì§€ ì•Šê³  ì„œë¡œë¥¼ ì‹ ë¢°í–ˆë‹¤. ë§ˆì¹¨ë‚´ êµ¬ì¡°ì„ ì´ ë„ì°©í•˜ê³ , ëª¨ë‘ê°€ ì•ˆì „í•˜ê²Œ ëŒì•„ê°„ë‹¤."
        }},
        {{
            "id": "ending_despair",
            "type": "tragic",
            "title": "ì ˆë§ì˜ ë‚˜ë½",
            "condition": "despair >= 70 AND trust <= 30",
            "summary": "ì ˆë§ì´ ëª¨ë“  ê²ƒì„ ì§‘ì–´ì‚¼ì¼°ë‹¤. ì„œë¡œì— ëŒ€í•œ ì‹ ë¢°ëŠ” ë¬´ë„ˆì§€ê³ , ë¹„ê·¹ì ì¸ ê²°ë§ì„ ë§ì´í•œë‹¤."
        }}
    ]
}}"""
        response = await self.llm.ainvoke(prompt)
        endings = self._parse_json(response.content).get("endings", [])

        # ë¹ˆ ê²°ê³¼ì¼ ê²½ìš° ê¸°ë³¸ê°’ ë°˜í™˜
        if not endings:
            print("  âš ï¸ ìµœì¢… ì—”ë”© ì„¤ê³„ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©")
            return [
                {
                    "id": "ending_default",
                    "type": "neutral",
                    "title": "ê¸°ë³¸ ì—”ë”©",
                    "condition": "default",
                    "summary": "ìŠ¤í† ë¦¬ê°€ ê¸°ë³¸ì ì¸ ê²°ë§ì— ë„ë‹¬í•©ë‹ˆë‹¤."
                }
            ]

        print(f"  âœ… {len(endings)}ê°œì˜ ìµœì¢… ì—”ë”© ì„¤ê³„ ì™„ë£Œ")
        return endings

    # --------------------------------------------------------------------------
    # [5ë‹¨ê³„] ì—í”¼ì†Œë“œ ë¶„í•  (Split into Episodes)
    # --------------------------------------------------------------------------
    async def split_into_episodes(self, novel_summary: str, characters: List[Character], num_episodes: int = 4) -> List[Dict]:
        print(f"ğŸ“š ì†Œì„¤ì„ {num_episodes}ê°œ ì—í”¼ì†Œë“œë¡œ ë¶„í•  ì¤‘...")

        # ìºë¦­í„° ì´ë¦„ ëª©ë¡
        char_names = [c.get('name', 'ì´ë¦„ì—†ìŒ') for c in characters]

        prompt = f"""ì£¼ì–´ì§„ ì†Œì„¤ì„ {num_episodes}ê°œì˜ ë…ë¦½ì ì¸ ì—í”¼ì†Œë“œë¡œ ë¶„í• í•˜ì„¸ìš”.

[ì†Œì„¤ ìš”ì•½]
{novel_summary}

[ë“±ì¥ì¸ë¬¼]
{', '.join(char_names)}

[ì¤‘ìš” ê·œì¹™]
- ê° ì—í”¼ì†Œë“œëŠ” ìŠ¤í† ë¦¬ìƒ ì„œë¡œ ì—°ê²°ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤ (ë…ë¦½ì )
- ì—í”¼ì†Œë“œ ê°„ì—ëŠ” ì˜¤ì§ ê²Œì´ì§€ë§Œ ëˆ„ì ë©ë‹ˆë‹¤
- ê° ì—í”¼ì†Œë“œëŠ” ìì²´ì ì¸ ì‹œì‘, ì „ê°œ, ì—”ë”©ì„ ê°€ì§‘ë‹ˆë‹¤

[ìš”êµ¬ì‚¬í•­]
ê° ì—í”¼ì†Œë“œì— ëŒ€í•´ ë‹¤ìŒì„ ì •ì˜í•˜ì„¸ìš”:
- id: ì˜ë¬¸ ì†Œë¬¸ì ì‹ë³„ì (ì˜ˆ: "ep1_encounter")
- title: ì—í”¼ì†Œë“œ ì œëª©
- order: ìˆœì„œ (1, 2, 3...)
- description: ì—í”¼ì†Œë“œ ìš”ì•½ (2-3ë¬¸ì¥)
- theme: í•µì‹¬ í…Œë§ˆ/ê°ˆë“± (ì˜ˆ: "ì‹ ë¢° vs ì˜ì‹¬", "í¬ë§ vs ì ˆë§")
- key_characters: ì£¼ìš” ë“±ì¥ì¸ë¬¼ ë¦¬ìŠ¤íŠ¸

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "episodes": [
        {{
            "id": "ep1_encounter",
            "title": "ì²« ë§Œë‚¨",
            "order": 1,
            "description": "ì£¼ì¸ê³µë“¤ì´ ì²˜ìŒ ë§Œë‚˜ ì„œë¡œë¥¼ ì•Œì•„ê°€ëŠ” ê³¼ì •. ì²«ì¸ìƒê³¼ ì´ˆê¸° ê´€ê³„ê°€ í˜•ì„±ëœë‹¤.",
            "theme": "ì‹ ë¢° í˜•ì„±",
            "key_characters": ["ë í”„", "ì­", "ìƒˆë¼ë¼ì§€"]
        }}
    ]
}}"""
        response = await self.llm.ainvoke(prompt)
        episodes = self._parse_json(response.content).get("episodes", [])

        if not episodes:
            print("  âš ï¸ ì—í”¼ì†Œë“œ ë¶„í•  ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©")
            return [
                {
                    "id": "ep1_default",
                    "title": "ì—í”¼ì†Œë“œ 1",
                    "order": 1,
                    "description": "ê¸°ë³¸ ì—í”¼ì†Œë“œ",
                    "theme": "ê¸°ë³¸",
                    "key_characters": char_names[:3]
                }
            ]

        print(f"  âœ… {len(episodes)}ê°œ ì—í”¼ì†Œë“œ ë¶„í•  ì™„ë£Œ")
        for ep in episodes:
            print(f"    â€¢ [{ep.get('order', '?')}] {ep.get('title', 'ì œëª©ì—†ìŒ')}: {ep.get('theme', '')}")

        return episodes

    # --------------------------------------------------------------------------
    # [5-2ë‹¨ê³„] ì—í”¼ì†Œë“œ ë„ì…ë¶€ ìƒì„± (Generate Episode Intro)
    # --------------------------------------------------------------------------
    async def generate_episode_intro(self, episode: Dict, characters: List[Character], novel_summary: str) -> str:
        print(f"  ğŸ¬ '{episode.get('title', '?')}' ë„ì…ë¶€ ìƒì„± ì¤‘...")

        # ìºë¦­í„° ì •ë³´
        char_names = [c.get('name', 'ì´ë¦„ì—†ìŒ') for c in characters]

        prompt = f"""ë‹¤ìŒ ì—í”¼ì†Œë“œì˜ ë„ì…ë¶€ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
í”Œë ˆì´ì–´ê°€ ì²« ë²ˆì§¸ ì„ íƒì§€ë¥¼ ë§Œë‚˜ê¸° ì „ì— ì½ê²Œ ë˜ëŠ” ìŠ¤í† ë¦¬ì…ë‹ˆë‹¤.

[ì†Œì„¤ ë°°ê²½]
{novel_summary}

[ì—í”¼ì†Œë“œ ì •ë³´]
- ì œëª©: {episode.get('title', '?')}
- ì„¤ëª…: {episode.get('description', '?')}
- í…Œë§ˆ: {episode.get('theme', '?')}
- ì£¼ìš” ë“±ì¥ì¸ë¬¼: {', '.join(episode.get('key_characters', char_names[:3]))}

[ì‘ì„± ìš”êµ¬ì‚¬í•­]
1. **ë¶„ëŸ‰**: 800~1200ì
2. **ë‚´ìš© í¬í•¨**:
   - í˜„ì¬ ìƒí™©ê³¼ ë°°ê²½ ì„¤ëª…
   - ë“±ì¥ì¸ë¬¼ë“¤ì˜ ëŒ€í™”ì™€ í–‰ë™
   - ë¶„ìœ„ê¸°ì™€ ê°ì • ë¬˜ì‚¬
   - ì—í”¼ì†Œë“œì˜ í•µì‹¬ ê°ˆë“±/í…Œë§ˆ ì•”ì‹œ
3. **ìŠ¤íƒ€ì¼**:
   - ì†Œì„¤ì²˜ëŸ¼ ìƒìƒí•˜ê²Œ ë¬˜ì‚¬
   - í”Œë ˆì´ì–´ê°€ ìƒí™©ì— ëª°ì…í•  ìˆ˜ ìˆë„ë¡
   - ë§ˆì§€ë§‰ì— ìì—°ìŠ¤ëŸ½ê²Œ ì„ íƒì˜ ìˆœê°„ìœ¼ë¡œ ì´ì–´ì§€ë„ë¡

ë„ì…ë¶€ í…ìŠ¤íŠ¸ë§Œ ì‘ì„±í•´ì£¼ì„¸ìš” (JSON ì•„ë‹˜):"""

        response = await self.llm.ainvoke(prompt)
        intro_text = response.content.strip()

        print(f"    âœ… ë„ì…ë¶€ ìƒì„± ì™„ë£Œ ({len(intro_text)}ì)")
        return intro_text

    # --------------------------------------------------------------------------
    # [6ë‹¨ê³„] ì—í”¼ì†Œë“œ ì—”ë”© ì„¤ê³„ (Design Episode Endings)
    # --------------------------------------------------------------------------
    async def design_episode_endings(self, episode: Dict, selected_gauges: List[Gauge], num_endings: int = 3) -> List[EpisodeEnding]:
        print(f"  ğŸ¯ '{episode.get('title', '?')}' ì—í”¼ì†Œë“œ ì—”ë”© ì„¤ê³„ ì¤‘...")

        # ê²Œì´ì§€ ì •ë³´ í¬ë§·íŒ…
        gauges_info = self._format_gauges(selected_gauges)

        prompt = f"""ì´ ì—í”¼ì†Œë“œì˜ {num_endings}ê°€ì§€ ì—”ë”©ì„ ì„¤ê³„í•˜ì„¸ìš”. ê° ì—”ë”©ì€ í”Œë ˆì´ì–´ì˜ ì„ íƒ íƒœê·¸ ëˆ„ì ì— ë”°ë¼ ë„ë‹¬í•˜ë©°, ê²Œì´ì§€ì— ì˜í–¥ì„ ì¤ë‹ˆë‹¤.

[ì—í”¼ì†Œë“œ ì •ë³´]
- ì œëª©: {episode.get('title', '?')}
- ì„¤ëª…: {episode.get('description', '?')}
- í…Œë§ˆ: {episode.get('theme', '?')}

[ê²Œì´ì§€ ì‹œìŠ¤í…œ]
{gauges_info}

[ì„ íƒì§€ íƒœê·¸ ì‹œìŠ¤í…œ]
í”Œë ˆì´ì–´ê°€ ì„ íƒì§€ë¥¼ ê³ ë¥¼ ë•Œë§ˆë‹¤ í•´ë‹¹ íƒœê·¸ê°€ ëˆ„ì ë©ë‹ˆë‹¤.
ì‚¬ìš© ê°€ëŠ¥í•œ íƒœê·¸: cooperative, aggressive, cautious, trusting, doubtful, brave, fearful, rational, emotional

[ì¤‘ìš”]
- ê° ì—”ë”©ì—ì„œë§Œ ê²Œì´ì§€ê°€ ë³€í™”í•©ë‹ˆë‹¤
- ê²Œì´ì§€ ë³€í™”ëŸ‰ì€ ì—”ë”©ì˜ ì¤‘ìš”ë„ì™€ ê·¹ì  íš¨ê³¼ì— ë”°ë¼ ììœ ë¡­ê²Œ ì„¤ì •í•˜ì„¸ìš”:
  - ì‘ì€ ì˜í–¥: -10 ~ +10
  - ë³´í†µ ì˜í–¥: -20 ~ +20
  - í° ì˜í–¥ (ê·¹ì ì¸ ì—”ë”©): -30 ~ +30
- conditionì€ íƒœê·¸ ì ìˆ˜ ê¸°ë°˜ ì¡°ê±´ì‹ìœ¼ë¡œ ì‘ì„± (ì˜ˆ: "cooperative >= 2", "trusting > doubtful")

[ìš”êµ¬ì‚¬í•­]
ê° ì—”ë”©ì— ëŒ€í•´ ë‹¤ìŒì„ ì •ì˜í•˜ì„¸ìš”:
- id: ì˜ë¬¸ ì†Œë¬¸ì ì‹ë³„ì
- title: ì—”ë”© ì œëª©
- condition: íƒœê·¸ ê¸°ë°˜ ì¡°ê±´ì‹ (ì˜ˆ: "cooperative >= 2 AND trusting >= 1")
- text: ì—”ë”© í…ìŠ¤íŠ¸ (3-5ë¬¸ì¥)
- gauge_changes: ê²Œì´ì§€ ë³€í™” (ì˜ˆ: {{'hope': 15, 'trust': 10}})

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "endings": [
        {{
            "id": "ep1_ending_trust",
            "title": "ì‹ ë¢°ì˜ ì‹œì‘",
            "condition": "cooperative >= 2 AND trusting >= 1",
            "text": "ì„œë¡œë¥¼ ì•Œì•„ê°€ë©° ì‹ ë¢°ê°€ ì‹¹í…„ë‹¤. ì•„ì§ ì™„ì „í•˜ì§€ëŠ” ì•Šì§€ë§Œ, í•¨ê»˜í•  ìˆ˜ ìˆë‹¤ëŠ” í¬ë§ì´ ìƒê²¼ë‹¤.",
            "gauge_changes": {{"hope": 10, "trust": 15}}
        }},
        {{
            "id": "ep1_ending_doubt",
            "title": "ì˜ì‹¬ì˜ ì”¨ì•—",
            "condition": "doubtful >= 2 OR aggressive >= 2",
            "text": "ì„œë¡œë¥¼ ê²½ê³„í•˜ë©° ê±°ë¦¬ë¥¼ ë‘ì—ˆë‹¤. ë¶ˆì‹ ì˜ ì”¨ì•—ì´ ë§ˆìŒ ì†ì— ì‹¬ì–´ì¡Œë‹¤.",
            "gauge_changes": {{"hope": -5, "trust": -10}}
        }},
        {{
            "id": "ep1_ending_neutral",
            "title": "ì¡°ì‹¬ìŠ¤ëŸ¬ìš´ ê´€ë§",
            "condition": "default",
            "text": "íŠ¹ë³„í•œ ì§„ì „ ì—†ì´ ì—í”¼ì†Œë“œê°€ ë§ˆë¬´ë¦¬ë˜ì—ˆë‹¤. ì•„ì§ ì„œë¡œì— ëŒ€í•´ ì•Œì•„ê°€ëŠ” ì¤‘ì´ë‹¤.",
            "gauge_changes": {{"hope": 0, "trust": 0}}
        }}
    ]
}}"""
        response = await self.llm.ainvoke(prompt)
        endings = self._parse_json(response.content).get("endings", [])

        if not endings:
            print(f"    âš ï¸ ì—í”¼ì†Œë“œ ì—”ë”© ì„¤ê³„ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©")
            return [
                {
                    "id": f"{episode.get('id', 'ep')}_ending_default",
                    "title": "ê¸°ë³¸ ì—”ë”©",
                    "condition": "ê¸°ë³¸",
                    "text": "ì—í”¼ì†Œë“œê°€ ëë‚¬ìŠµë‹ˆë‹¤.",
                    "gauge_changes": {{}}
                }
            ]

        print(f"    âœ… {len(endings)}ê°œ ì—”ë”© ì„¤ê³„ ì™„ë£Œ")
        return endings

    # --------------------------------------------------------------------------
    # [5ë‹¨ê³„] ìŠ¤í† ë¦¬ íŠ¸ë¦¬ ìƒì„± (Generate Story Tree - LangGraph Engine)
    # --------------------------------------------------------------------------
    async def generate_full_tree(self, context: Dict, max_depth: int = 3) -> List[StoryNode]:
        """
        LangGraphë¥¼ ì‚¬ìš©í•˜ì—¬ ì „ì²´ ìŠ¤í† ë¦¬ íŠ¸ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            context: ìºë¦­í„°, ê²Œì´ì§€, ì—”ë”©, êµ¬ì¡°ê°€ì´ë“œ, ì†Œì„¤ìš”ì•½ ë“± ëª¨ë“  ì»¨í…ìŠ¤íŠ¸ ì •ë³´
            max_depth: íŠ¸ë¦¬ì˜ ìµœëŒ€ ê¹Šì´ (ê¸°ë³¸ê°’: 3)

        Returns:
            ìƒì„±ëœ ëª¨ë“  StoryNode ë¦¬ìŠ¤íŠ¸

        Note:
            - ê¹Šì´ 0: ë£¨íŠ¸ ë…¸ë“œ (1ê°œ)
            - ê¹Šì´ 1: ë£¨íŠ¸ì˜ ì„ íƒì§€ ìˆ˜ë§Œí¼ (ì˜ˆ: 3ê°œ)
            - ê¹Šì´ 2: ê¹Šì´1 ë…¸ë“œë“¤ì˜ ì„ íƒì§€ ì´í•© (ì˜ˆ: 9ê°œ)
            - ...
            - ê¸°í•˜ê¸‰ìˆ˜ì ìœ¼ë¡œ ì¦ê°€í•˜ë¯€ë¡œ max_depthë¥¼ ì ì ˆíˆ ì„¤ì •í•´ì•¼ í•¨
        """
        print(f"ğŸŒ³ ìŠ¤í† ë¦¬ íŠ¸ë¦¬ ìƒì„± ì—”ì§„ ê°€ë™... (ìµœëŒ€ ê¹Šì´: {max_depth})")

        # ì˜ˆìƒ ë…¸ë“œ ìˆ˜ ê³„ì‚° (ì„ íƒì§€ê°€ í‰ê·  3ê°œë¼ ê°€ì •)
        avg_choices = 3
        estimated_nodes = sum([avg_choices ** d for d in range(max_depth + 1)])
        print(f"  ğŸ“Š ì˜ˆìƒ ë…¸ë“œ ìˆ˜: ì•½ {estimated_nodes}ê°œ")

        # LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±
        workflow = StateGraph(StoryGenerationState)
        workflow.add_node("generate_node", self._node_generator)
        workflow.add_edge(START, "generate_node")
        workflow.add_conditional_edges("generate_node", self._plan_next_step)

        app = workflow.compile()

        # ì´ˆê¸° ê²Œì´ì§€ ìƒíƒœ ì„¤ì • (AIê°€ ì œì•ˆí•œ initial_value ì‚¬ìš©, ì—†ìœ¼ë©´ 50)
        initial_gauges = {}
        for gauge in context.get("gauges", []):
            gauge_id = gauge.get("id", gauge.get("name", "unknown"))
            initial_gauges[gauge_id] = gauge.get("initial_value", 50)

        # ì´ˆê¸° ìƒíƒœ ì£¼ì…
        initial_state: StoryGenerationState = {
            "nodes": [],
            "context": context,
            "max_depth": max_depth,
            "current_gauges": initial_gauges
        }

        try:
            final_state = await app.ainvoke(initial_state)
            nodes = final_state.get("nodes", [])

            print(f"âœ… íŠ¸ë¦¬ ìƒì„± ì™„ë£Œ! ì´ {len(nodes)}ê°œ ë…¸ë“œ ìƒì„±ë¨")

            # íŠ¸ë¦¬ êµ¬ì¡° ìš”ì•½ ì¶œë ¥
            self._print_tree_summary(nodes)

            return nodes

        except Exception as e:
            print(f"âŒ íŠ¸ë¦¬ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise

    def _print_tree_summary(self, nodes: List[StoryNode]):
        """ìƒì„±ëœ íŠ¸ë¦¬ êµ¬ì¡° ìš”ì•½ ì¶œë ¥"""
        if not nodes:
            return

        depth_counts = {}
        for node in nodes:
            depth = node.get("depth", 0)
            depth_counts[depth] = depth_counts.get(depth, 0) + 1

        print("\nğŸ“ˆ íŠ¸ë¦¬ êµ¬ì¡° ìš”ì•½:")
        for depth in sorted(depth_counts.keys()):
            count = depth_counts[depth]
            indent = "  " * depth
            print(f"  {indent}ê¹Šì´ {depth}: {count}ê°œ ë…¸ë“œ")

    # --- LangGraph ë‚´ë¶€ ë¡œì§ (Worker) ---
    async def _node_generator(self, state: Dict):
        """ì‹¤ì œ LLMì„ í˜¸ì¶œí•˜ì—¬ ìŠ¤í† ë¦¬ ë…¸ë“œë¥¼ ìƒì„±í•˜ëŠ” ì›Œì»¤"""

        # Sendë¡œ ì „ë‹¬ëœ task ì •ë³´ ë˜ëŠ” ì´ˆê¸° ìƒíƒœì—ì„œ ì¶”ì¶œ
        if "task" in state:
            task = state["task"]
            depth = task["depth"]
            parent = task.get("parent_node")
            choice_taken = task.get("choice_taken")
            context = state["context"]
        else:
            # ì´ˆê¸° ë£¨íŠ¸ ë…¸ë“œ ìƒì„±
            depth = 0
            parent = None
            choice_taken = None
            context = state["context"]

        # ë…¸ë“œ íƒ€ì… ê²°ì • (AIê°€ ì„ íƒì§€ ê°œìˆ˜ëŠ” ìë™ íŒë‹¨)
        max_depth = state.get("max_depth", 5)
        if depth == max_depth:
            node_type = "ending"
        elif depth == 0:
            node_type = "first_choice"
        elif depth == max_depth - 1:
            node_type = "climax"
        else:
            node_type = "development"

        # ìºë¦­í„° ì •ë³´ í¬ë§·íŒ…
        characters_info = self._format_characters(context.get("characters", []))

        # ê²Œì´ì§€ ì •ë³´ í¬ë§·íŒ…
        gauges_info = self._format_gauges(context.get("gauges", []))

        # ì—”ë”© ì •ë³´ í¬ë§·íŒ…
        endings_info = self._format_endings(context.get("endings", []))

        # ì´ì „ ìŠ¤í† ë¦¬ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        previous_context = ""
        if parent:
            previous_context = f"\n[ì´ì „ ìŠ¤í† ë¦¬]\n{parent.get('text', '')}\n\n[í”Œë ˆì´ì–´ì˜ ì„ íƒ]\n{choice_taken.get('text', '') if choice_taken else '(ì‹œì‘)'}"

        # í˜„ì¬ ê²Œì´ì§€ ìƒíƒœ ê³„ì‚°
        current_gauges = self._calculate_current_gauges(state, choice_taken)

        system_prompt = f"""ë‹¹ì‹ ì€ ì¸í„°ë™í‹°ë¸Œ ì†Œì„¤ ì‘ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìŠ¤í† ë¦¬ ë…¸ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

[ì†Œì„¤ ë°°ê²½]
{context.get('novel_summary', 'ì •ë³´ ì—†ìŒ')}

[ë“±ì¥ì¸ë¬¼]
{characters_info}

[ê²Œì´ì§€ ì‹œìŠ¤í…œ]
{gauges_info}

[í˜„ì¬ ê²Œì´ì§€ ìƒíƒœ]
{json.dumps(current_gauges, ensure_ascii=False)}

[ê°€ëŠ¥í•œ ì—”ë”©ë“¤]
{endings_info}

[í˜„ì¬ ë…¸ë“œ ì •ë³´]
- ê¹Šì´: {depth}/{max_depth}
- ë…¸ë“œ íƒ€ì…: {node_type}
- ì„ íƒì§€ ê°œìˆ˜: ìƒí™©ì— ë§ê²Œ 2~4ê°œ ì¤‘ ìë™ ê²°ì •

{previous_context}"""

        user_prompt = f"""ìœ„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ìŠ¤í† ë¦¬ ë…¸ë“œë¥¼ ìƒì„±í•˜ì„¸ìš”.

[ì‘ì„± ìš”êµ¬ì‚¬í•­]
1. **ìŠ¤í† ë¦¬ ë³¸ë¬¸** (500-800ì): í˜„ì¬ ìƒí™©ì„ ìƒìƒí•˜ê²Œ ë¬˜ì‚¬. ìºë¦­í„°ë“¤ì˜ ëŒ€í™”ì™€ í–‰ë™ í¬í•¨.
2. **ë””í…Œì¼ ì •ë³´**:
   - npc_emotions: í˜„ì¬ ë“±ì¥í•˜ëŠ” NPCë“¤ì˜ ê°ì • ìƒíƒœ (ì˜ˆ: {{'ë í”„': 'ë¶ˆì•ˆ', 'ì­': 'í¥ë¶„'}})
   - situation: í˜„ì¬ ìƒí™© í•œ ì¤„ ìš”ì•½
   - relations_update: ì´ë²ˆ ì¥ë©´ìœ¼ë¡œ ì¸í•œ ì¸ë¬¼ ê´€ê³„ ë³€í™” (ì˜ˆ: {{'ë í”„-ì­': 'ì ëŒ€ê° ìƒìŠ¹'}})
3. **ì„ íƒì§€** (2~4ê°œ, ìƒí™©ì— ë§ê²Œ íŒë‹¨):
   - ì„ íƒì§€ ê°œìˆ˜ëŠ” í˜„ì¬ ìƒí™©ì˜ ë³µì¡ë„ì™€ ì¤‘ìš”ë„ì— ë”°ë¼ 2~4ê°œ ì¤‘ ì ì ˆíˆ ê²°ì •í•˜ì„¸ìš”
     - ë‹¨ìˆœí•œ ìƒí™©, ê¸´ë°•í•œ ìˆœê°„: 2ê°œ
     - ì¼ë°˜ì ì¸ ìƒí™©: 3ê°œ
     - ì¤‘ìš”í•œ ë¶„ê¸°ì , ë‹¤ì–‘í•œ ì ‘ê·¼ì´ ê°€ëŠ¥í•œ ìƒí™©: 4ê°œ
   - ì„ íƒì§€ í…ìŠ¤íŠ¸ëŠ” í”Œë ˆì´ì–´ ê´€ì ì—ì„œ 1ì¸ì¹­ìœ¼ë¡œ ì‘ì„±
   - ê° ì„ íƒì§€ì— íŠ¹ì„± íƒœê·¸ í¬í•¨ (1~2ê°œì”©)
   - ì‚¬ìš© ê°€ëŠ¥í•œ íƒœê·¸: cooperative, aggressive, cautious, trusting, doubtful, brave, fearful, rational, emotional

{"âš ï¸ ì´ê²ƒì€ ì—í”¼ì†Œë“œ ì—”ë”©ìœ¼ë¡œ ì—°ê²°ë˜ëŠ” ë…¸ë“œì…ë‹ˆë‹¤. ìŠ¤í† ë¦¬ë¥¼ ì ì ˆíˆ ë§ˆë¬´ë¦¬í•˜ê³  ì„ íƒì§€ëŠ” ë¹ˆ ë°°ì—´ë¡œ ë‘ì„¸ìš”." if node_type == "ending" else ""}

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "text": "ìŠ¤í† ë¦¬ ë³¸ë¬¸...",
    "details": {{
        "npc_emotions": {{"ìºë¦­í„°ëª…": "ê°ì •"}},
        "situation": "ìƒí™© ìš”ì•½",
        "relations_update": {{ "ê´€ê³„": "ë³€í™” ë‚´ìš©" }}
    }},
    "choices": [
        {{
            "text": "ì„ íƒì§€ í…ìŠ¤íŠ¸",
            "tags": ["cooperative", "trusting"]
        }},
        {{
            "text": "ë‹¤ë¥¸ ì„ íƒì§€",
            "tags": ["aggressive", "doubtful"]
        }}
    ]
}}"""

        try:
            response = await self.llm.ainvoke([
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt)
            ])

            parsed = self._parse_json(response.content)

            # ë…¸ë“œ ID ìƒì„±
            node_id = str(uuid.uuid4())[:8]

            # ë…¸ë“œ êµ¬ì„±
            new_node: StoryNode = {
                "id": node_id,
                "depth": depth,
                "text": parsed.get("text", "ìŠ¤í† ë¦¬ ìƒì„± ì‹¤íŒ¨"),
                "details": parsed.get("details", {
                    "npc_emotions": {},
                    "situation": "ì•Œ ìˆ˜ ì—†ìŒ",
                    "relations_update": {}
                }),
                "choices": parsed.get("choices", []),
                "parent_id": parent["id"] if parent else None,
                "node_type": node_type,
                "episode_id": context.get("episode_id", "unknown")
            }

            print(f"  âœ… ë…¸ë“œ ìƒì„± ì™„ë£Œ: depth={depth}, id={node_id}, choices={len(new_node['choices'])}")

            return {"nodes": [new_node], "current_gauges": current_gauges}

        except Exception as e:
            print(f"  âŒ ë…¸ë“œ ìƒì„± ì‹¤íŒ¨ (depth={depth}): {e}")
            # í´ë°± ë…¸ë“œ ìƒì„±
            fallback_node: StoryNode = {
                "id": str(uuid.uuid4())[:8],
                "depth": depth,
                "text": f"[ì˜¤ë¥˜ë¡œ ì¸í•´ ìŠ¤í† ë¦¬ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}]",
                "details": {
                    "npc_emotions": {},
                    "situation": "ì˜¤ë¥˜ ë°œìƒ",
                    "relations_update": {}
                },
                "choices": [],
                "parent_id": parent["id"] if parent else None,
                "node_type": "error",
                "episode_id": context.get("episode_id", "unknown")
            }
            return {"nodes": [fallback_node], "current_gauges": current_gauges}

    def _format_characters(self, characters: List[Character]) -> str:
        """ìºë¦­í„° ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ìš© ë¬¸ìì—´ë¡œ í¬ë§·íŒ…"""
        if not characters:
            return "ë“±ë¡ëœ ìºë¦­í„° ì—†ìŒ"

        result = []
        for char in characters:
            # cite íƒœê·¸ ì œê±°í•˜ì—¬ í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš© (ê°„ê²°í•˜ê²Œ)
            description = char.get('description', 'ì •ë³´ ì—†ìŒ')
            # [cite: ...] íŒ¨í„´ ì œê±°
            import re
            clean_desc = re.sub(r'\\\[cite:.*?\\\\]', '', description).strip()
            # ë„ˆë¬´ ê¸¸ë©´ ì¤„ì„
            if len(clean_desc) > 300:
                clean_desc = clean_desc[:300] + "..."

            char_info = f"""â€¢ {char.get('name', 'ì´ë¦„ì—†ìŒ')} (ë³„ëª…: {', '.join(char.get('aliases', []))})
  - ì„¤ëª…: {clean_desc}
  - ê´€ê³„: {'; '.join(char.get('relationships', [])[:3])}"""
            result.append(char_info)

        return "\n".join(result)

    def _format_gauges(self, gauges: List[Gauge]) -> str:
        """ê²Œì´ì§€ ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ìš© ë¬¸ìì—´ë¡œ í¬ë§·íŒ…"""
        if not gauges:
            return "ë“±ë¡ëœ ê²Œì´ì§€ ì—†ìŒ"

        result = []
        for g in gauges:
            gauge_info = f"""â€¢ {g.get('name', 'ì´ë¦„ì—†ìŒ')} (id: {g.get('id', 'unknown')})
  - ì˜ë¯¸: {g.get('meaning', 'ë¶ˆëª…')}
  - 0: {g.get('min_label', 'ìµœì†Œ')} â†” 100: {g.get('max_label', 'ìµœëŒ€')}"""
            result.append(gauge_info)

        return "\n".join(result)

    def _format_endings(self, endings: List[FinalEnding]) -> str:
        """ì—”ë”© ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ìš© ë¬¸ìì—´ë¡œ í¬ë§·íŒ…"""
        if not endings:
            return "ë“±ë¡ëœ ì—”ë”© ì—†ìŒ"

        result = []
        for e in endings:
            ending_info = f"""â€¢ [{e.get('type', 'unknown')}] {e.get('title', 'ì œëª©ì—†ìŒ')}
  - ì¡°ê±´: {e.get('condition', 'ë¶ˆëª…')}"""
            result.append(ending_info)

        return "\n".join(result)

    def _calculate_current_gauges(self, state: Dict, choice_taken: Optional[StoryChoice]) -> Dict[str, int]:
        """í˜„ì¬ ê²Œì´ì§€ ìƒíƒœ ê³„ì‚°"""
        # ì´ˆê¸°ê°’ ì„¤ì • (ëª¨ë“  ê²Œì´ì§€ 50ì—ì„œ ì‹œì‘)
        current = state.get("current_gauges", {})
        if not current:
            for g in state.get("context", {}).get("gauges", []):
                current[g.get("id", g.get("name", "unknown"))] = 50
        else:
            current = current.copy()

        # ì„ íƒì— ë”°ë¥¸ ê²Œì´ì§€ ë³€í™” ì ìš©
        if choice_taken and "gauge_changes" in choice_taken:
            for gauge_id, change in choice_taken["gauge_changes"].items():
                if gauge_id in current:
                    current[gauge_id] = max(0, min(100, current[gauge_id] + change))
                else:
                    current[gauge_id] = max(0, min(100, 50 + change))

        return current

    # --- LangGraph ë‚´ë¶€ ë¡œì§ (Manager) ---
    def _plan_next_step(self, state):
        """
        Map-Reduce íŒ¨í„´ì„ ì‚¬ìš©í•œ íŠ¸ë¦¬ ë¶„ê¸° ë¡œì§

        - ê° ë…¸ë“œì˜ ì„ íƒì§€ë§ˆë‹¤ ìƒˆë¡œìš´ ìì‹ ë…¸ë“œë¥¼ ìƒì„±
        - ìµœëŒ€ ê¹Šì´ì— ë„ë‹¬í•˜ë©´ ì¢…ë£Œ
        - ì„ íƒì§€ê°€ ì—†ëŠ” ë…¸ë“œ(ì—”ë”©)ëŠ” ë” ì´ìƒ ë¶„ê¸°í•˜ì§€ ì•ŠìŒ
        """
        nodes = state.get("nodes", [])
        max_depth = state.get("max_depth", 5)
        context = state.get("context", {})
        current_gauges = state.get("current_gauges", {})

        # ì•„ì§ ë…¸ë“œê°€ ì—†ìœ¼ë©´ ë£¨íŠ¸ ë…¸ë“œ ìƒì„±ì„ ìœ„í•´ ì´ˆê¸° ìƒíƒœ ë°˜í™˜
        if not nodes:
            return [Send("generate_node", {
                "context": context,
                "max_depth": max_depth,
                "current_gauges": current_gauges
            })]

        # ê°€ì¥ ìµœê·¼ì— ìƒì„±ëœ ë…¸ë“œë“¤ ì°¾ê¸° (ê°™ì€ ê¹Šì´ì˜ ë…¸ë“œë“¤)
        # LangGraphì˜ Map-Reduceì—ì„œëŠ” ë³‘ë ¬ë¡œ ìƒì„±ëœ ë…¸ë“œë“¤ì´ í•œ ë²ˆì— ì¶”ê°€ë¨
        if len(nodes) == 1:
            latest_nodes = nodes
        else:
            # ê°€ì¥ ê¹Šì€ depthì˜ ë…¸ë“œë“¤ì„ ì°¾ìŒ
            max_current_depth = max(n["depth"] for n in nodes)
            latest_nodes = [n for n in nodes if n["depth"] == max_current_depth]

        # ìµœëŒ€ ê¹Šì´ ì²´í¬
        if latest_nodes and latest_nodes[0]["depth"] > max_depth:
            print(f"ğŸ ìµœëŒ€ ê¹Šì´ {max_depth} ë„ë‹¬. íŠ¸ë¦¬ ìƒì„± ì™„ë£Œ.")
            return END

        # ê° ìµœì‹  ë…¸ë“œì˜ ì„ íƒì§€ì— ëŒ€í•´ ìì‹ ë…¸ë“œ ìƒì„± íƒœìŠ¤í¬ ìƒì„±
        tasks = []
        for node in latest_nodes:
            choices = node.get("choices", [])

            if not choices:
                # ì„ íƒì§€ê°€ ì—†ëŠ” ë…¸ë“œ (ì—”ë”© ë˜ëŠ” ì—ëŸ¬)ëŠ” ìŠ¤í‚µ
                continue

            for choice_idx, choice in enumerate(choices):
                # ì´ ì„ íƒì§€ë¥¼ ì„ íƒí–ˆì„ ë•Œì˜ ìì‹ ë…¸ë“œ ìƒì„± íƒœìŠ¤í¬
                task = {
                    "task": {
                        "depth": node["depth"] + 1,
                        "parent_node": node,
                        "choice_taken": choice,
                        "choice_index": choice_idx
                    },
                    "context": context,
                    "max_depth": max_depth,
                    "current_gauges": current_gauges
                }
                tasks.append(Send("generate_node", task))
                print(f"  ğŸ“ íƒœìŠ¤í¬ ì˜ˆì•½: depth={node['depth']+1}, parent={node['id']}, choice={choice_idx}")

        if not tasks:
            print("ğŸ ë” ì´ìƒ ìƒì„±í•  ë…¸ë“œê°€ ì—†ìŠµë‹ˆë‹¤. íŠ¸ë¦¬ ìƒì„± ì™„ë£Œ.")
            return END

        print(f"ğŸ”€ {len(tasks)}ê°œì˜ ë¶„ê¸° ë…¸ë“œ ìƒì„± ì‹œì‘...")
        return tasks

    # ìœ í‹¸ë¦¬í‹°
    def _parse_json(self, content: str) -> Dict:
        """LLM ì‘ë‹µì—ì„œ JSONì„ ì•ˆì „í•˜ê²Œ íŒŒì‹±"""
        try:
            # ë¨¼ì € LangChain íŒŒì„œ ì‹œë„
            return self.json_parser.parse(content)
        except Exception:
            pass

        # ì§ì ‘ JSON ì¶”ì¶œ ì‹œë„
        try:
            # ```json ... ``` ë¸”ë¡ ì¶”ì¶œ
            json_match = re.search(r'```(?:json)?\s*([\s\S]*?)\s*```', content)
            if json_match:
                json_str = json_match.group(1).strip()
                return json.loads(json_str)

            # { } ë¸”ë¡ ì§ì ‘ ì¶”ì¶œ (ê°€ì¥ í° JSON ê°ì²´ ì°¾ê¸°)
            json_match = re.search(r'\{[\s\S]*\}', content)
            if json_match:
                json_str = json_match.group(0).strip()
                return json.loads(json_str)

            # ì§ì ‘ íŒŒì‹± ì‹œë„
            return json.loads(content.strip())

        except json.JSONDecodeError as e:
            print(f"  âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            # ë””ë²„ê¹…ì„ ìœ„í•´ ì‘ë‹µì˜ ì¼ë¶€ ì¶œë ¥
            preview = content[:300] if len(content) > 300 else content
            print(f"  ğŸ“„ ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {preview}")

        return {}

    async def _generate_summary(self, novel_text: str) -> str:
        """ì†Œì„¤ í…ìŠ¤íŠ¸ ìš”ì•½ ìƒì„± - ì²­í¬ ë¶„í•  í›„ í†µí•© ìš”ì•½"""
        chunk_size = 20000  # ê° ì²­í¬ í¬ê¸°

        if len(novel_text) <= chunk_size:
            # ì§§ì€ í…ìŠ¤íŠ¸ëŠ” ë°”ë¡œ ìš”ì•½
            prompt = f"""ë‹¤ìŒ ì†Œì„¤ í…ìŠ¤íŠ¸ë¥¼ 500ì ë‚´ì™¸ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
í•µì‹¬ ì¤„ê±°ë¦¬, ì£¼ì œ, ê°ˆë“± êµ¬ì¡°, ê²°ë§ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.

[ì†Œì„¤ í…ìŠ¤íŠ¸]
{novel_text}
"""
            response = await self.llm.ainvoke(prompt)
            return response.content

        # ê¸´ í…ìŠ¤íŠ¸ëŠ” ì²­í¬ë¡œ ë‚˜ëˆ ì„œ ê°ê° ìš”ì•½
        print(f"  ğŸ“š ê¸´ í…ìŠ¤íŠ¸ ê°ì§€ ({len(novel_text):,}ì), ì²­í¬ ë¶„í•  ìš”ì•½ ì‹œì‘...")

        chunks = []
        for i in range(0, len(novel_text), chunk_size):
            chunks.append(novel_text[i:i + chunk_size])

        print(f"  ğŸ“¦ {len(chunks)}ê°œ ì²­í¬ë¡œ ë¶„í• ")

        # ê° ì²­í¬ ìš”ì•½
        chunk_summaries = []
        for i, chunk in enumerate(chunks):
            print(f"    [{i+1}/{len(chunks)}] ì²­í¬ ìš”ì•½ ì¤‘...")
            prompt = f"""ë‹¤ìŒì€ ì†Œì„¤ì˜ {i+1}ë²ˆì§¸ ë¶€ë¶„ì…ë‹ˆë‹¤. ì´ ë¶€ë¶„ì˜ í•µì‹¬ ë‚´ìš©ì„ 200ì ë‚´ì™¸ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
ì£¼ìš” ì‚¬ê±´, ë“±ì¥ì¸ë¬¼ì˜ í–‰ë™, ê°ˆë“±ì„ í¬í•¨í•˜ì„¸ìš”.

[í…ìŠ¤íŠ¸]
{chunk}
"""
            response = await self.llm.ainvoke(prompt)
            chunk_summaries.append(f"[íŒŒíŠ¸ {i+1}] {response.content}")

        # ì²­í¬ ìš”ì•½ë“¤ì„ í†µí•©í•˜ì—¬ ìµœì¢… ìš”ì•½
        print("  ğŸ”„ ì²­í¬ ìš”ì•½ í†µí•© ì¤‘...")
        combined_summaries = "\n\n".join(chunk_summaries)

        final_prompt = f"""ë‹¤ìŒì€ ì†Œì„¤ì˜ ê° ë¶€ë¶„ë³„ ìš”ì•½ì…ë‹ˆë‹¤. ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ì²´ ì†Œì„¤ì„ 500ì ë‚´ì™¸ë¡œ í†µí•© ìš”ì•½í•´ì£¼ì„¸ìš”.
í•µì‹¬ ì¤„ê±°ë¦¬, ì£¼ì œ, ê°ˆë“± êµ¬ì¡°, ê²°ë§ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.

[ë¶€ë¶„ë³„ ìš”ì•½]
{combined_summaries}
"""
        response = await self.llm.ainvoke(final_prompt)
        print("  âœ… í†µí•© ìš”ì•½ ì™„ë£Œ")

        return response.content


# ==============================================================================
# 3. LangGraph ìƒíƒœ ì •ì˜ (State Definition)
# ==============================================================================

def merge_gauges(current: Dict[str, int], new: Dict[str, int]) -> Dict[str, int]:
    """ê²Œì´ì§€ ìƒíƒœ ë³‘í•© (ìµœì‹  ê°’ìœ¼ë¡œ ì—…ë°ì´íŠ¸)"""
    if not new:
        return current
    result = current.copy() if current else {}
    result.update(new)
    return result

class StoryGenerationState(TypedDict):
    nodes: Annotated[List[StoryNode], operator.add]
    context: Dict[str, Any]  # ìºë¦­í„°, ì†Œì„¤ìš”ì•½, ê²Œì´ì§€, ì—”ë”©, ê°€ì´ë“œ ë“± ëª¨ë“  ì •ë³´
    max_depth: int
    current_gauges: Annotated[Dict[str, int], merge_gauges]  # í˜„ì¬ ê²Œì´ì§€ ìƒíƒœ
